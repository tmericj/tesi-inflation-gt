{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb40e65",
   "metadata": {},
   "source": [
    "### Script Python per Unire e Filtrare Dati NIC da Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758bdd0",
   "metadata": {},
   "source": [
    "Questo script unisce e filtra dati mensili dell’Indice Generale NIC provenienti da due file Excel (anni 1996-2015 il primo, 2016-2024 il secondo), entrambi a frequenza mensile, destagionalizzati e con base 2015=100.\n",
    "\n",
    "Estrae la serie desiderata da ciascun file, la trasforma in formato lungo, unisce i dati, rimuove duplicati, ordina cronologicamente e salva il risultato finale in un file CSV pronto per l’analisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d981951f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processamento File 1: /Users/tommaso/Desktop/tesi-inflation-gt/ISTAT_data/Reconstruction NIC base 2015 (1996-2015).xls ---\n",
      "Utilizzo di 'xlrd' engine per il file .xls.\n",
      "File 1 (foglio 'IT') caricato. Nomi colonne letti (primi 10): ['ECOICOP', 'livello', 'denominazioni 2016', datetime.datetime(1996, 1, 1, 0, 0), datetime.datetime(1996, 2, 1, 0, 0), datetime.datetime(1996, 3, 1, 0, 0), datetime.datetime(1996, 4, 1, 0, 0), datetime.datetime(1996, 5, 1, 0, 0), datetime.datetime(1996, 6, 1, 0, 0), datetime.datetime(1996, 7, 1, 0, 0)]\n",
      "Riga 'Indice generale NIC' trovata nel File 1.\n",
      "Trovate 240 colonne di tipo datetime nel File 1.\n",
      "Colonne mese (datetime) identificate e filtrate nel File 1 (conteggio): 144\n",
      "Esempio colonne filtrate (prime 3): [datetime.datetime(2004, 1, 1, 0, 0), datetime.datetime(2004, 2, 1, 0, 0), datetime.datetime(2004, 3, 1, 0, 0)]\n",
      "Esempio colonne filtrate (ultime 3): [datetime.datetime(2015, 10, 1, 0, 0), datetime.datetime(2015, 11, 1, 0, 0), datetime.datetime(2015, 12, 1, 0, 0)]\n",
      "File 1 processato. Righe dopo melt e dropna: 144\n",
      "Test File 1 - Periodo min: 2004-01-01 00:00:00, Periodo max: 2015-12-01 00:00:00\n",
      "\n",
      "--- Processamento File 2: /Users/tommaso/Desktop/tesi-inflation-gt/ISTAT_data/Principali dati (IT1,167_744_DF_DCSP_NIC1B2015_1,1.0).xlsx ---\n",
      "File 2 (foglio 'M IT 39 4') caricato. Nomi colonne (primi 10): ['Tempo  ', '2016-01  ', '2016-02  ', '2016-03  ', '2016-04  ', '2016-05  ', '2016-06  ', '2016-07  ', '2016-08  ', '2016-09  ']\n",
      "Colonna descrittiva identificata nel File 2: 'Tempo  '\n",
      "Riga '00 Indice generale' trovata nel File 2.\n",
      "Colonne mese identificate nel File 2 (conteggio): 108\n",
      "File 2 processato. Righe dopo melt e dropna: 108\n",
      "Test File 2 - Periodo min: 2016-01-01 00:00:00, Periodo max: 2024-12-01 00:00:00\n",
      "\n",
      "--- Unione e Finalizzazione ---\n",
      "Righe da File 1: 144, Righe da File 2: 108\n",
      "Rimozione di eventuali duplicati basati sul Periodo (mantenendo il primo)...\n",
      "Ordinamento cronologico del dataset unificato...\n",
      "Dataset unificato creato. Numero righe totali: 252\n",
      "Periodo coperto: da 2004-01-01 a 2024-12-01\n",
      "\n",
      "Filtraggio dati da 2004-01-01 a 2024-12-31...\n",
      "Dataset filtrato. Numero righe: 252\n",
      "Periodo filtrato coperto: da 2004-01-01 a 2024-12-01\n",
      "Prime 5 righe del dataset filtrato:\n",
      "               Periodo  Valore_NIC\n",
      "0  2004-01-01 00:00:00        82.0\n",
      "1  2004-02-01 00:00:00        82.2\n",
      "2  2004-03-01 00:00:00        82.5\n",
      "3  2004-04-01 00:00:00        82.7\n",
      "4  2004-05-01 00:00:00        82.9\n",
      "\n",
      "Ultime 5 righe del dataset filtrato:\n",
      "                 Periodo  Valore_NIC\n",
      "247  2024-08-01 00:00:00       121.4\n",
      "248  2024-09-01 00:00:00       121.2\n",
      "249  2024-10-01 00:00:00       121.2\n",
      "250  2024-11-01 00:00:00       121.1\n",
      "251  2024-12-01 00:00:00       121.2\n",
      "\n",
      "Directory di output '/Users/tommaso/Desktop/tesi-inflation-gt/ISTAT_data' verificata/creata.\n",
      "Dataset finale salvato con successo in: /Users/tommaso/Desktop/tesi-inflation-gt/ISTAT_data/NIC_unificato_2004_2024_finale_v3.csv\n",
      "\n",
      "Script terminato.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# --- PARAMETRI DI CONFIGURARZIONE ---\n",
    "# Percorsi completi dei file Excel di input\n",
    "file_excel_1_path = \"/Users/tommaso/Desktop/tesi-inflation-gt/ISTAT_data/Reconstruction NIC base 2015 (1996-2015).xls\"\n",
    "file_excel_2_path = \"/Users/tommaso/Desktop/tesi-inflation-gt/ISTAT_data/Principali dati (IT1,167_744_DF_DCSP_NIC1B2015_1,1.0).xlsx\"\n",
    "\n",
    "# Directory di output specificata\n",
    "output_directory = \"/Users/tommaso/Desktop/tesi-inflation-gt/ISTAT_data\"\n",
    "# Nome del file CSV di output\n",
    "output_filename = \"NIC_unificato_2004_2024_finale_v3.csv\"\n",
    "# --- FINE DEI PARAMETRI DI CONFIGURAZIONE ---\n",
    "\n",
    "# --- FUNZIONI DI PROCESSAMENTO DATI ---\n",
    "def process_file_1(file_path):\n",
    "    \"\"\"\n",
    "    Processa il primo file Excel (1996-2015).\n",
    "    Estrae i dati dell'Indice Generale NIC, li trasforma da wide a long,\n",
    "    e seleziona il periodo da Gennaio 2004 a Dicembre 2015.\n",
    "    \"\"\"\n",
    "    print(f\"--- Processamento File 1: {file_path} ---\")\n",
    "    engine_to_use = None\n",
    "    if file_path.endswith('.xls'):\n",
    "        engine_to_use = 'xlrd'\n",
    "        print(\"Utilizzo di 'xlrd' engine per il file .xls.\")\n",
    "    \n",
    "    try:\n",
    "        df1 = pd.read_excel(file_path, sheet_name=\"IT\", header=10, engine=engine_to_use)\n",
    "        print(f\"File 1 (foglio 'IT') caricato. Nomi colonne letti (primi 10): {df1.columns.tolist()[:10]}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERRORE: File 1 non trovato: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERRORE durante la lettura del File 1 (foglio 'IT', header=10): {e}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        riga_indice_generale = df1[\n",
    "            (df1['ECOICOP'].astype(str).str.strip() == \"00\") &\n",
    "            (df1['livello'].astype(str).str.strip() == \"Gen.\") &\n",
    "            (df1['denominazioni 2016'].astype(str).str.strip() == \"Indice generale NIC\")\n",
    "        ].copy()\n",
    "    except KeyError as ke:\n",
    "        print(f\"ERRORE: Una delle colonne chiave ('ECOICOP', 'livello', 'denominazioni 2016') non è stata trovata. \"\n",
    "              f\"Verifica che 'header=10' sia corretto e che i nomi colonna corrispondano. Errore: {ke}\")\n",
    "        return None\n",
    "\n",
    "    if riga_indice_generale.empty:\n",
    "        print(\"ERRORE: Riga 'Indice generale NIC' non trovata nel File 1 con i criteri specificati.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Riga 'Indice generale NIC' trovata nel File 1.\")\n",
    "\n",
    "    # Identifico le colonne dei mesi che sono già state lette come datetime\n",
    "    colonne_datetime_file1 = [col for col in riga_indice_generale.columns if isinstance(col, datetime)]\n",
    "    \n",
    "    if not colonne_datetime_file1:\n",
    "        print(\"ERRORE: Nessuna colonna di tipo datetime (per i mesi) trovata nel File 1 dopo il caricamento.\")\n",
    "        print(f\"Tipi di dato delle colonne (primi 10): {riga_indice_generale.dtypes[:10]}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Trovate {len(colonne_datetime_file1)} colonne di tipo datetime nel File 1.\")\n",
    "\n",
    "    # Filtro queste colonne datetime per l'intervallo Gen 2004 - Dic 2015\n",
    "    data_inizio_periodo_file1 = datetime(2004, 1, 1)\n",
    "    data_fine_periodo_file1 = datetime(2015, 12, 1) # Consideriamo il primo del mese\n",
    "\n",
    "    colonne_mesi_da_estrarre_file1 = [\n",
    "        col for col in colonne_datetime_file1 \n",
    "        if data_inizio_periodo_file1 <= col <= data_fine_periodo_file1\n",
    "    ]\n",
    "\n",
    "    if not colonne_mesi_da_estrarre_file1:\n",
    "        print(f\"ERRORE: Nessuna colonna datetime trovata nell'intervallo {data_inizio_periodo_file1.strftime('%Y-%m')} - {data_fine_periodo_file1.strftime('%Y-%m')} nel File 1.\")\n",
    "        print(f\"Esempio di colonne datetime trovate (prime 5): {colonne_datetime_file1[:5]}\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"Colonne mese (datetime) identificate e filtrate nel File 1 (conteggio): {len(colonne_mesi_da_estrarre_file1)}\")\n",
    "    print(f\"Esempio colonne filtrate (prime 3): {colonne_mesi_da_estrarre_file1[:3]}\")\n",
    "    print(f\"Esempio colonne filtrate (ultime 3): {colonne_mesi_da_estrarre_file1[-3:]}\")\n",
    "\n",
    "\n",
    "    # Seleziono solo le colonne identificate (che sono già datetime) e le prime colonne identificative\n",
    "    colonne_identificative = ['ECOICOP', 'livello', 'denominazioni 2016']\n",
    "    # Mi assicuro che le colonne identificative esistano prima di usarle\n",
    "    existing_id_cols = [col for col in colonne_identificative if col in riga_indice_generale.columns]\n",
    "    \n",
    "    dati_selezionati = riga_indice_generale[existing_id_cols + colonne_mesi_da_estrarre_file1]\n",
    "\n",
    "    # Trasformo da wide a long (unpivot)\n",
    "    # id_vars saranno le colonne che non devono essere \"unpivoted\"\n",
    "    df1_long = dati_selezionati.melt(\n",
    "        id_vars=existing_id_cols, \n",
    "        value_vars=colonne_mesi_da_estrarre_file1,\n",
    "        var_name=\"Periodo\", # Questa colonna conterrà direttamente gli oggetti datetime\n",
    "        value_name=\"Valore_NIC\"\n",
    "    )\n",
    "    \n",
    "    # 'Periodo' è già datetime, non serve ulteriore conversione da stringa.\n",
    "    df1_long.dropna(subset=['Periodo', 'Valore_NIC'], inplace=True)\n",
    "\n",
    "    print(f\"File 1 processato. Righe dopo melt e dropna: {len(df1_long)}\")\n",
    "    if not df1_long.empty:\n",
    "        print(f\"Test File 1 - Periodo min: {df1_long['Periodo'].min()}, Periodo max: {df1_long['Periodo'].max()}\")\n",
    "    return df1_long[['Periodo', 'Valore_NIC']]\n",
    "\n",
    "def process_file_2(file_path):\n",
    "    \"\"\"\n",
    "    Processa il secondo file Excel (2016-2024).\n",
    "    Estrae i dati dell'Indice Generale NIC e li trasforma da wide a long.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Processamento File 2: {file_path} ---\")\n",
    "    try:\n",
    "        df2 = pd.read_excel(file_path, sheet_name=\"M IT 39 4\", header=6)\n",
    "        print(f\"File 2 (foglio 'M IT 39 4') caricato. Nomi colonne (primi 10): {df2.columns.tolist()[:10]}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERRORE: File 2 non trovato: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERRORE durante la lettura del File 2 (foglio 'M IT 39 4', header=6): {e}\")\n",
    "        return None\n",
    "\n",
    "    desc_col_name = df2.columns[0] \n",
    "    print(f\"Colonna descrittiva identificata nel File 2: '{desc_col_name}'\")\n",
    "    \n",
    "    try:\n",
    "        # Mi assicurato che la colonna descrittiva sia trattata come stringa per il confronto\n",
    "        riga_indice_generale = df2[df2[desc_col_name].astype(str).str.contains(\"00 Indice generale\", na=False, case=False, regex=False)].copy()\n",
    "    except KeyError:\n",
    "        print(f\"ERRORE: Colonna descrittiva '{desc_col_name}' non trovata nel File 2 dopo aver impostato header=6.\")\n",
    "        return None\n",
    "\n",
    "    if riga_indice_generale.empty:\n",
    "        print(f\"ERRORE: Riga '00 Indice generale' non trovata nel File 2 (colonna '{desc_col_name}').\")\n",
    "        print(f\"Contenuto della colonna '{desc_col_name}' (prime 5 righe del df2):\\n{df2[desc_col_name].head()}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Riga '00 Indice generale' trovata nel File 2.\")\n",
    "\n",
    "    colonne_dati_valide_per_melt = []\n",
    "    for col in riga_indice_generale.columns[1:]:\n",
    "        col_name_str = str(col).strip()\n",
    "        if col_name_str:\n",
    "            try:\n",
    "                datetime.strptime(col_name_str, \"%Y-%m\") # Verifica del formato AAAA-MM\n",
    "                colonne_dati_valide_per_melt.append(col)\n",
    "            except ValueError:\n",
    "                if isinstance(col, datetime): # Se pandas l'ha già parsato come datetime\n",
    "                     colonne_dati_valide_per_melt.append(col)\n",
    "                else:\n",
    "                    print(f\"Attenzione: colonna '{col}' nel File 2 scartata (nome '{col_name_str}' non è AAAA-MM o datetime).\")\n",
    "        else:\n",
    "            print(f\"Attenzione: colonna con nome vuoto/spazi scartata nel File 2.\")\n",
    "\n",
    "    if not colonne_dati_valide_per_melt:\n",
    "        print(\"ERRORE: Nessuna colonna mese valida (formato AAAA-MM o datetime) trovata nel File 2.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Colonne mese identificate nel File 2 (conteggio): {len(colonne_dati_valide_per_melt)}\")\n",
    "    dati_selezionati = riga_indice_generale[colonne_dati_valide_per_melt]\n",
    "    \n",
    "    df2_long = dati_selezionati.melt(var_name=\"Periodo_Testo\", value_name=\"Valore_NIC\")\n",
    "\n",
    "    def convert_periodo_file2(periodo_obj):\n",
    "        if isinstance(periodo_obj, datetime):\n",
    "            return periodo_obj\n",
    "        periodo_str = str(periodo_obj).strip()\n",
    "        try:\n",
    "            return datetime.strptime(periodo_str, \"%Y-%m\")\n",
    "        except ValueError:\n",
    "            print(f\"Attenzione: formato data non riconosciuto per '{periodo_obj}' nel File 2.\")\n",
    "            return None\n",
    "            \n",
    "    df2_long['Periodo'] = df2_long['Periodo_Testo'].apply(convert_periodo_file2)\n",
    "    df2_long.dropna(subset=['Periodo', 'Valore_NIC'], inplace=True) # Rimuovo anche se Valore_NIC è NaN\n",
    "\n",
    "    print(f\"File 2 processato. Righe dopo melt e dropna: {len(df2_long)}\")\n",
    "    if not df2_long.empty:\n",
    "        print(f\"Test File 2 - Periodo min: {df2_long['Periodo'].min()}, Periodo max: {df2_long['Periodo'].max()}\")\n",
    "    return df2_long[['Periodo', 'Valore_NIC']]\n",
    "\n",
    "# --- ESECUZIONE DELLO SCRIPT ---\n",
    "df1_processed = process_file_1(file_excel_1_path)\n",
    "df2_processed = process_file_2(file_excel_2_path)\n",
    "\n",
    "if df1_processed is not None and not df1_processed.empty and \\\n",
    "   df2_processed is not None and not df2_processed.empty:\n",
    "    \n",
    "    print(\"\\n--- Unione e Finalizzazione ---\")\n",
    "    print(f\"Righe da File 1: {len(df1_processed)}, Righe da File 2: {len(df2_processed)}\")\n",
    "    df_unificato = pd.concat([df1_processed, df2_processed], ignore_index=True)\n",
    "\n",
    "    df_unificato['Valore_NIC'] = pd.to_numeric(df_unificato['Valore_NIC'], errors='coerce')\n",
    "    df_unificato.dropna(subset=['Valore_NIC', 'Periodo'], inplace=True)\n",
    "\n",
    "    print(\"Rimozione di eventuali duplicati basati sul Periodo (mantenendo il primo)...\")\n",
    "    df_unificato.drop_duplicates(subset=['Periodo'], keep='first', inplace=True)\n",
    "\n",
    "    print(\"Ordinamento cronologico del dataset unificato...\")\n",
    "    df_unificato.sort_values('Periodo', inplace=True)\n",
    "    \n",
    "    print(f\"Dataset unificato creato. Numero righe totali: {len(df_unificato)}\")\n",
    "    if not df_unificato.empty:\n",
    "        print(f\"Periodo coperto: da {df_unificato['Periodo'].min().strftime('%Y-%m-%d')} a {df_unificato['Periodo'].max().strftime('%Y-%m-%d')}\\n\")\n",
    "\n",
    "        data_inizio_filtro = pd.to_datetime(\"2004-01-01\")\n",
    "        data_fine_filtro = pd.to_datetime(\"2024-12-31\")\n",
    "\n",
    "        print(f\"Filtraggio dati da {data_inizio_filtro.strftime('%Y-%m-%d')} a {data_fine_filtro.strftime('%Y-%m-%d')}...\")\n",
    "        \n",
    "        df_filtrato = df_unificato[\n",
    "            (df_unificato['Periodo'] >= data_inizio_filtro) &\n",
    "            (df_unificato['Periodo'] <= data_fine_filtro)\n",
    "        ].copy()\n",
    "\n",
    "        print(f\"Dataset filtrato. Numero righe: {len(df_filtrato)}\")\n",
    "        if not df_filtrato.empty:\n",
    "            print(f\"Periodo filtrato coperto: da {df_filtrato['Periodo'].min().strftime('%Y-%m-%d')} a {df_filtrato['Periodo'].max().strftime('%Y-%m-%d')}\")\n",
    "            print(f\"Prime 5 righe del dataset filtrato:\\n{df_filtrato.head()}\\n\")\n",
    "            print(f\"Ultime 5 righe del dataset filtrato:\\n{df_filtrato.tail()}\\n\")\n",
    "\n",
    "            try:\n",
    "                os.makedirs(output_directory, exist_ok=True)\n",
    "                print(f\"Directory di output '{output_directory}' verificata/creata.\")\n",
    "            except OSError as e:\n",
    "                print(f\"ERRORE: Impossibile creare la directory di output '{output_directory}': {e}\")\n",
    "                print(\"Salvataggio annullato.\")\n",
    "            else:\n",
    "                full_output_path = os.path.join(output_directory, output_filename)\n",
    "                try:\n",
    "                    df_filtrato_save = df_filtrato.copy()\n",
    "                    # Converto esplicitamente Periodo in datetime\n",
    "                    df_filtrato_save['Periodo'] = pd.to_datetime(df_filtrato_save['Periodo'])\n",
    "                    # Formatto la colonna Periodo come AAAA-MM\n",
    "                    df_filtrato_save['Periodo'] = df_filtrato_save['Periodo'].dt.strftime('%Y-%m')\n",
    "        \n",
    "                    df_filtrato_save.to_csv(full_output_path, index=False)\n",
    "                    print(f\"Dataset finale salvato con successo in: {full_output_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"ERRORE durante il salvataggio del file CSV '{full_output_path}': {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Il dataset filtrato è vuoto. Controlla le date di filtro e i dati originali.\")\n",
    "    else:\n",
    "        print(\"Il dataset unificato è vuoto. Problemi durante il processamento dei file.\")\n",
    "else:\n",
    "    print(\"\\nUno o entrambi i file Excel non sono stati processati correttamente o non hanno prodotto dati validi. Impossibile procedere con l'unione.\")\n",
    "    if df1_processed is None or df1_processed.empty :\n",
    "        print(\"Problema specifico con il File 1 o il suo output.\")\n",
    "    if df2_processed is None or df2_processed.empty:\n",
    "        print(\"Problema specifico con il File 2 o il suo output.\")\n",
    "\n",
    "\n",
    "print(\"\\nScript terminato.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_python_env)",
   "language": "python",
   "name": "my_python_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
