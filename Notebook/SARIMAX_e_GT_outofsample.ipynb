{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "401ab29f",
   "metadata": {},
   "source": [
    "## Out of Sample Analysis\n",
    "\n",
    "Analisi Out-of-Sample del modello SARIMAX base e con tutte le aggiunte.\n",
    "Confronto sistematico di modelli di forecasting con test statistici avanzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d3891c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Framework inizializzato\n",
      "Output directory: /Users/tommaso/Desktop/tesi-inflation-gt/SARIMAX_modelli/previsioni_out_of_sample_v3_avanzata\n",
      "\n",
      "====================\n",
      "ANALISI OUT-OF-SAMPLE PROFESSIONALE\n",
      "Framework per Valutazione Modelli di Forecasting\n",
      "====================\n",
      "\n",
      "============================================================\n",
      " FASE 1: CARICAMENTO E PREPARAZIONE DATI\n",
      "============================================================\n",
      "\n",
      "Caricamento dati da: indici_gt_nic_stazionari_fase2.csv\n",
      "Dati caricati: 252 osservazioni, 3 variabili\n",
      "\n",
      "Serie target: NIC_destag_ISTAT_diff1\n",
      "   - Periodo: 2004-02 a 2024-12\n",
      "   - Osservazioni valide: 251\n",
      "\n",
      "Preparazione variabili esogene per modello:\n",
      "   â€¢ Base_Outliers: 2 variabili esogene\n",
      "   â€¢ GT_Tematico_L1: 3 variabili esogene\n",
      "   â€¢ GT_Inflazione_L3: 3 variabili esogene\n",
      "   â€¢ GT_Entrambi: 4 variabili esogene\n",
      "\n",
      "Preparazione dati completata con successo\n",
      "\n",
      "============================================================\n",
      "FASE 2: GENERAZIONE PREVISIONI OUT-OF-SAMPLE\n",
      "   Schema: rolling | Finestra: 180 mesi\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Modello: Base_Outliers\n",
      "   SARIMA(1, 0, 1)(0, 0, 0, 12)\n",
      "   â†’ Esecuzione 60 iterazioni di forecasting...\n",
      "      Progresso: 100.0% - ETA: 0s\n",
      "      âœ“ Completate 60/60 iterazioni\n",
      "   â€¢ h=1: 60 previsioni generate\n",
      "   â€¢ h=3: 60 previsioni generate\n",
      "   â€¢ h=6: 60 previsioni generate\n",
      "   â€¢ h=12: 60 previsioni generate\n",
      "\n",
      "ðŸ“Š Modello: GT_Tematico_L1\n",
      "   SARIMA(1, 0, 1)(0, 0, 0, 12)\n",
      "   â†’ Esecuzione 59 iterazioni di forecasting...\n",
      "      Progresso: 84.7% - ETA: 0s\n",
      "      âœ“ Completate 59/59 iterazioni\n",
      "   â€¢ h=1: 59 previsioni generate\n",
      "   â€¢ h=3: 59 previsioni generate\n",
      "   â€¢ h=6: 59 previsioni generate\n",
      "   â€¢ h=12: 59 previsioni generate\n",
      "\n",
      "ðŸ“Š Modello: GT_Inflazione_L3\n",
      "   SARIMA(1, 0, 1)(0, 0, 0, 12)\n",
      "   â†’ Esecuzione 57 iterazioni di forecasting...\n",
      "      Progresso: 87.7% - ETA: 0s\n",
      "      âœ“ Completate 57/57 iterazioni\n",
      "   â€¢ h=1: 57 previsioni generate\n",
      "   â€¢ h=3: 57 previsioni generate\n",
      "   â€¢ h=6: 57 previsioni generate\n",
      "   â€¢ h=12: 57 previsioni generate\n",
      "\n",
      "ðŸ“Š Modello: GT_Entrambi\n",
      "   SARIMA(1, 0, 1)(0, 0, 0, 12)\n",
      "   â†’ Esecuzione 57 iterazioni di forecasting...\n",
      "      Progresso: 87.7% - ETA: 0s\n",
      "      âœ“ Completate 57/57 iterazioni\n",
      "   â€¢ h=1: 57 previsioni generate\n",
      "   â€¢ h=3: 57 previsioni generate\n",
      "   â€¢ h=6: 57 previsioni generate\n",
      "   â€¢ h=12: 57 previsioni generate\n",
      "\n",
      "Previsioni completate per 4 modelli\n",
      "\n",
      "============================================================\n",
      "FASE 3: CALCOLO METRICHE DI ACCURATEZZA\n",
      "============================================================\n",
      "\n",
      "Tabella Riepilogativa Metriche:\n",
      "\n",
      "RMSE per Orizzonte:\n",
      "+------------------+--------+--------+--------+--------+\n",
      "| Modello          |      1 |      3 |      6 |     12 |\n",
      "+==================+========+========+========+========+\n",
      "| Base_Outliers    | 0.5964 | 0.5969 | 0.656  | 0.7033 |\n",
      "+------------------+--------+--------+--------+--------+\n",
      "| GT_Entrambi      | 0.6131 | 0.6131 | 0.6598 | 0.7166 |\n",
      "+------------------+--------+--------+--------+--------+\n",
      "| GT_Inflazione_L3 | 0.6117 | 0.6137 | 0.6637 | 0.7151 |\n",
      "+------------------+--------+--------+--------+--------+\n",
      "| GT_Tematico_L1   | 0.6038 | 0.6009 | 0.6574 | 0.7111 |\n",
      "+------------------+--------+--------+--------+--------+\n",
      "\n",
      "MAE per Orizzonte:\n",
      "+------------------+--------+--------+--------+--------+\n",
      "| Modello          |      1 |      3 |      6 |     12 |\n",
      "+==================+========+========+========+========+\n",
      "| Base_Outliers    | 0.3722 | 0.3633 | 0.4059 | 0.4195 |\n",
      "+------------------+--------+--------+--------+--------+\n",
      "| GT_Entrambi      | 0.3787 | 0.3723 | 0.4033 | 0.4223 |\n",
      "+------------------+--------+--------+--------+--------+\n",
      "| GT_Inflazione_L3 | 0.3819 | 0.3778 | 0.4062 | 0.4271 |\n",
      "+------------------+--------+--------+--------+--------+\n",
      "| GT_Tematico_L1   | 0.3748 | 0.3611 | 0.4093 | 0.4203 |\n",
      "+------------------+--------+--------+--------+--------+\n",
      "\n",
      "Migliori Modelli per Orizzonte:\n",
      "   h=1: Base_Outliers (RMSE=0.5964)\n",
      "   h=3: Base_Outliers (RMSE=0.5969)\n",
      "   h=6: Base_Outliers (RMSE=0.6560)\n",
      "   h=12: Base_Outliers (RMSE=0.7033)\n",
      "\n",
      "============================================================\n",
      "FASE 4: TEST STATISTICI AVANZATI\n",
      "============================================================\n",
      "\n",
      "Orizzonte h=1:\n",
      "\n",
      "Orizzonte h=3:\n",
      "\n",
      "Orizzonte h=6:\n",
      "\n",
      "Orizzonte h=12:\n",
      "\n",
      "Salvati 24 test Diebold-Mariano\n",
      "Salvati 12 test Clark-West\n",
      "Salvati 24 test Encompassing\n",
      "\n",
      "============================================================\n",
      "FASE 5: GENERAZIONE REPORT E GRAFICI\n",
      "============================================================\n",
      "Grafico metriche salvato: metriche_confronto_rolling.png\n",
      "Heatmap performance salvata: heatmap_performance_rolling.png\n",
      "Grafico accuratezza direzionale salvato: accuratezza_direzionale_rolling.png\n",
      "\n",
      "Report testuale salvato: report_finale_rolling.txt\n",
      "Configurazione salvata: configurazione_esperimento.json\n",
      "\n",
      "Report e grafici completati con successo!\n",
      "\n",
      "============================================================\n",
      "ANALISI COMPLETATA CON SUCCESSO!\n",
      "Tutti i risultati salvati in: /Users/tommaso/Desktop/tesi-inflation-gt/SARIMAX_modelli/previsioni_out_of_sample_v3_avanzata\n",
      "============================================================\n",
      "\n",
      "Tempo totale di esecuzione: 11.1 secondi\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from dieboldmariano import dm_test\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "\n",
    "# Configurazione warnings\n",
    "warnings.filterwarnings(\"ignore\", category=sm.tools.sm_exceptions.ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# ==================== CONFIGURAZIONE ====================\n",
    "class Config:\n",
    "    \"\"\"Configurazione centralizzata dell'analisi\"\"\"\n",
    "    \n",
    "    # Percorsi\n",
    "    PATH_INPUT_DIR_FASE2 = \"/Users/tommaso/Desktop/tesi-inflation-gt/First_Difference_indexes/dati_preparati_fase2\"\n",
    "    FILE_SERIE_STAZIONARIE_IN = os.path.join(PATH_INPUT_DIR_FASE2, \"indici_gt_nic_stazionari_fase2.csv\")\n",
    "    PATH_OUTPUT_OOS = \"/Users/tommaso/Desktop/tesi-inflation-gt/SARIMAX_modelli/previsioni_out_of_sample_v3_avanzata\"\n",
    "    \n",
    "    # Nomi colonne\n",
    "    COL_INFLAZIONE_STAZ = 'NIC_destag_ISTAT_diff1'\n",
    "    COL_GT_INFLAZIONE_ORIG = 'indice_Inflazione_GT_PCA_SA_diff1'\n",
    "    COL_GT_TEMATICO_ORIG = 'indice_Tematico_GT_SA_diff1'\n",
    "    \n",
    "    # Parametri analisi\n",
    "    LUNGHEZZA_FINESTRA_INIZIALE = 180\n",
    "    ORIZZONTI_PREVISIONE = [1, 3, 6, 12]\n",
    "    SCHEMA_PREVISIONE = \"rolling\"  # \"rolling\" o \"recursive\"\n",
    "    MIN_OBS_FORECAST_TESTS = 20\n",
    "    ALPHA_LEVEL = 0.05\n",
    "    N_BOOTSTRAP_SPA = 1000\n",
    "    \n",
    "    # Configurazione modelli\n",
    "    MODELLI_DA_TESTARE = {\n",
    "        \"Base_Outliers\": {\n",
    "            \"order\": (1, 0, 1), \n",
    "            \"seasonal_order\": (0, 0, 0, 12),\n",
    "            \"exog_vars_base\": [\"d_outlier_2022_01_1m\", \"d_outlier_2022_10_1m\"], \n",
    "            \"gt_vars_lags\": {}\n",
    "        },\n",
    "        \"GT_Tematico_L1\": {\n",
    "            \"order\": (1, 0, 1), \n",
    "            \"seasonal_order\": (0, 0, 0, 12),\n",
    "            \"exog_vars_base\": [\"d_outlier_2022_01_1m\", \"d_outlier_2022_10_1m\"],\n",
    "            \"gt_vars_lags\": {\"indice_Tematico_GT_SA_diff1\": 1}\n",
    "        },\n",
    "        \"GT_Inflazione_L3\": {\n",
    "            \"order\": (1, 0, 1), \n",
    "            \"seasonal_order\": (0, 0, 0, 12),\n",
    "            \"exog_vars_base\": [\"d_outlier_2022_01_1m\", \"d_outlier_2022_10_1m\"],\n",
    "            \"gt_vars_lags\": {\"indice_Inflazione_GT_PCA_SA_diff1\": 3}\n",
    "        },\n",
    "        \"GT_Entrambi\": {\n",
    "            \"order\": (1, 0, 1), \n",
    "            \"seasonal_order\": (0, 0, 0, 12),\n",
    "            \"exog_vars_base\": [\"d_outlier_2022_01_1m\", \"d_outlier_2022_10_1m\"],\n",
    "            \"gt_vars_lags\": {\n",
    "                \"indice_Inflazione_GT_PCA_SA_diff1\": 3, \n",
    "                \"indice_Tematico_GT_SA_diff1\": 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "# ==================== FUNZIONI DI TEST STATISTICO ====================\n",
    "def clark_west_test(actual: np.ndarray, pred_restricted: np.ndarray, \n",
    "                   pred_unrestricted: np.ndarray, horizon: int = 1) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Test di Clark-West per modelli nested.\n",
    "    Come confrontare due strategie d'investimento dove una Ã¨ versione semplificata dell'altra.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        actual = np.asarray(actual).flatten()\n",
    "        pred_r = np.asarray(pred_restricted).flatten()\n",
    "        pred_u = np.asarray(pred_unrestricted).flatten()\n",
    "        \n",
    "        # Verifica lunghezze\n",
    "        if len(actual) != len(pred_r) or len(actual) != len(pred_u):\n",
    "            return np.nan, np.nan\n",
    "            \n",
    "        error_r = actual - pred_r\n",
    "        error_u = actual - pred_u\n",
    "        mse_diff = error_r**2 - error_u**2\n",
    "        adj_diff = (pred_u - pred_r)**2\n",
    "        cw_stat_series = mse_diff + adj_diff\n",
    "        \n",
    "        mean_cw = np.mean(cw_stat_series)\n",
    "        n = len(cw_stat_series)\n",
    "        \n",
    "        if n == 0:\n",
    "            return np.nan, np.nan\n",
    "            \n",
    "        # Correzione Newey-West per autocorrelazione\n",
    "        bandwidth = max(1, int(4 * (n/100)**(2/9)))\n",
    "        centered_series = cw_stat_series - mean_cw\n",
    "        gamma_0 = np.mean(centered_series**2)\n",
    "        gamma_sum = 0\n",
    "        \n",
    "        for j in range(1, min(bandwidth + 1, n)):\n",
    "            if n - j > 0:\n",
    "                gamma_j = np.mean(centered_series[j:] * centered_series[:-j])\n",
    "                weight = 1 - j / (bandwidth + 1)\n",
    "                gamma_sum += 2 * weight * gamma_j\n",
    "                \n",
    "        variance_cw = (gamma_0 + gamma_sum) / n\n",
    "        \n",
    "        if variance_cw > 1e-9:\n",
    "            t_stat = mean_cw / np.sqrt(variance_cw)\n",
    "            p_value = 1 - stats.norm.cdf(t_stat)\n",
    "        else:\n",
    "            t_stat = np.nan\n",
    "            p_value = np.nan\n",
    "            \n",
    "        return t_stat, p_value\n",
    "        \n",
    "    except Exception:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "\n",
    "def encompassing_test(actual: np.ndarray, pred1: np.ndarray, \n",
    "                     pred2: np.ndarray) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Test di encompassing: verifica se un modello ingloba le informazioni dell'altro.\n",
    "    Come verificare se un analista senior incorpora giÃ  tutte le intuizioni di un junior.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        actual = np.asarray(actual).flatten()\n",
    "        pred1 = np.asarray(pred1).flatten()\n",
    "        pred2 = np.asarray(pred2).flatten()\n",
    "        \n",
    "        if len(actual) != len(pred1) or len(actual) != len(pred2):\n",
    "            return np.nan, np.nan, np.nan\n",
    "            \n",
    "        errors1 = actual - pred1\n",
    "        pred_diff = pred1 - pred2\n",
    "        \n",
    "        X = sm.add_constant(pred_diff, prepend=True)\n",
    "        \n",
    "        if X.shape[0] < X.shape[1] + 1:\n",
    "            return np.nan, np.nan, np.nan\n",
    "            \n",
    "        model = sm.OLS(errors1, X).fit()\n",
    "        t_stat_beta = model.tvalues[1]\n",
    "        p_value_beta = model.pvalues[1]\n",
    "        beta_hat = model.params[1]\n",
    "        \n",
    "        return t_stat_beta, p_value_beta, beta_hat\n",
    "        \n",
    "    except Exception:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "\n",
    "def spa_test(actual: np.ndarray, predictions_dict: Dict[str, np.ndarray], \n",
    "            benchmark_model_name: str, n_bootstrap: int = 1000) -> Tuple[float, float, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Superior Predictive Ability test di Hansen.\n",
    "    Come un torneo dove verifichi se esiste almeno una strategia che batte significativamente il benchmark.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        actual = np.asarray(actual).flatten()\n",
    "        n_obs = len(actual)\n",
    "        \n",
    "        if benchmark_model_name not in predictions_dict:\n",
    "            return np.nan, np.nan, {}\n",
    "            \n",
    "        benchmark_pred = np.asarray(predictions_dict[benchmark_model_name]).flatten()\n",
    "        benchmark_errors_sq = (actual - benchmark_pred)**2\n",
    "        \n",
    "        relative_performance_loss_diff = {}\n",
    "        \n",
    "        for model_name, predictions in predictions_dict.items():\n",
    "            if model_name != benchmark_model_name:\n",
    "                model_pred = np.asarray(predictions).flatten()\n",
    "                if len(model_pred) == n_obs:\n",
    "                    model_errors_sq = (actual - model_pred)**2\n",
    "                    relative_performance_loss_diff[model_name] = benchmark_errors_sq - model_errors_sq\n",
    "                \n",
    "        if not relative_performance_loss_diff:\n",
    "            return 0, 1.0, {}\n",
    "            \n",
    "        mean_loss_diffs = {name: np.mean(diffs) for name, diffs in relative_performance_loss_diff.items()}\n",
    "        observed_max_avg_improvement = max(0, max(mean_loss_diffs.values())) if mean_loss_diffs else 0\n",
    "        \n",
    "        # Bootstrap\n",
    "        bootstrap_max_avg_improvements = []\n",
    "        d_series_matrix = np.array([diffs for diffs in relative_performance_loss_diff.values()]).T\n",
    "        \n",
    "        for _ in range(n_bootstrap):\n",
    "            bootstrap_indices = np.random.choice(n_obs, n_obs, replace=True)\n",
    "            d_bootstrap_sample = d_series_matrix[bootstrap_indices, :]\n",
    "            \n",
    "            if d_bootstrap_sample.size > 0:\n",
    "                mean_d_bootstrap = np.mean(d_bootstrap_sample, axis=0)\n",
    "                current_bootstrap_max = max(0, max(mean_d_bootstrap)) if len(mean_d_bootstrap) > 0 else 0\n",
    "            else:\n",
    "                current_bootstrap_max = 0\n",
    "                \n",
    "            bootstrap_max_avg_improvements.append(current_bootstrap_max)\n",
    "            \n",
    "        p_value = np.mean(np.array(bootstrap_max_avg_improvements) >= observed_max_avg_improvement)\n",
    "        \n",
    "        return observed_max_avg_improvement, p_value, mean_loss_diffs\n",
    "        \n",
    "    except Exception:\n",
    "        return np.nan, np.nan, {}\n",
    "\n",
    "\n",
    "# ==================== CLASSE PRINCIPALE ====================\n",
    "class ForecastingFramework:\n",
    "    \"\"\"\n",
    "    Framework per analisi out-of-sample di modelli di forecasting.\n",
    "    Come un sistema di backtesting per strategie finanziarie in condizioni reali.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.results_metrics = []\n",
    "        self.all_series_data = None\n",
    "        self.target_series_clean = None\n",
    "        self.exog_data_prepared = {}\n",
    "        self.all_forecast_results = {}\n",
    "        \n",
    "        Path(self.config.PATH_OUTPUT_OOS).mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"\\nFramework inizializzato\")\n",
    "        print(f\"Output directory: {self.config.PATH_OUTPUT_OOS}\")\n",
    "\n",
    "    def _create_pulse_dummy(self, index: pd.DatetimeIndex, event_date_str: str, \n",
    "                           duration_months: int, base_name: str) -> pd.Series:\n",
    "        \"\"\"Crea variabili dummy per eventi specifici\"\"\"\n",
    "        event_ts = pd.Timestamp(event_date_str)\n",
    "        dummy = pd.Series(0, index=index, name=base_name)\n",
    "        event_mask = (index >= event_ts) & (index < event_ts + pd.DateOffset(months=duration_months))\n",
    "        dummy[event_mask] = 1\n",
    "        return dummy\n",
    "\n",
    "    def load_and_prepare_data(self) -> bool:\n",
    "        \"\"\"\n",
    "        Carica e prepara i dati, gestendo correttamente i duplicati.\n",
    "        Come preparare dati storici di mercato per backtesting puliti e allineati.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\" FASE 1: CARICAMENTO E PREPARAZIONE DATI\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        try:\n",
    "            # Caricamento dati\n",
    "            print(f\"\\nCaricamento dati da: {os.path.basename(self.config.FILE_SERIE_STAZIONARIE_IN)}\")\n",
    "            self.all_series_data = pd.read_csv(self.config.FILE_SERIE_STAZIONARIE_IN, index_col=0)\n",
    "            self.all_series_data.index = pd.to_datetime(self.all_series_data.index)\n",
    "            \n",
    "            # CORREZIONE CRITICA: Gestione duplicati nell'indice\n",
    "            if self.all_series_data.index.duplicated().any():\n",
    "                n_duplicates = self.all_series_data.index.duplicated().sum()\n",
    "                print(f\"Trovati {n_duplicates} duplicati nell'indice - rimozione in corso...\")\n",
    "                self.all_series_data = self.all_series_data[~self.all_series_data.index.duplicated(keep='last')]\n",
    "            \n",
    "            self.all_series_data = self.all_series_data.asfreq('MS')\n",
    "            print(f\"Dati caricati: {self.all_series_data.shape[0]} osservazioni, {self.all_series_data.shape[1]} variabili\")\n",
    "            \n",
    "            # Preparazione serie target\n",
    "            if self.config.COL_INFLAZIONE_STAZ not in self.all_series_data.columns:\n",
    "                print(f\"Errore: variabile target '{self.config.COL_INFLAZIONE_STAZ}' non trovata\")\n",
    "                return False\n",
    "                \n",
    "            self.target_series_clean = self.all_series_data[self.config.COL_INFLAZIONE_STAZ].dropna()\n",
    "            print(f\"\\nSerie target: {self.config.COL_INFLAZIONE_STAZ}\")\n",
    "            print(f\"   - Periodo: {self.target_series_clean.index[0].strftime('%Y-%m')} a {self.target_series_clean.index[-1].strftime('%Y-%m')}\")\n",
    "            print(f\"   - Osservazioni valide: {len(self.target_series_clean)}\")\n",
    "            \n",
    "            # Preparazione variabili esogene per ogni modello\n",
    "            print(\"\\nPreparazione variabili esogene per modello:\")\n",
    "            for model_name, config in self.config.MODELLI_DA_TESTARE.items():\n",
    "                exog_list = []\n",
    "                \n",
    "                # Dummy outliers\n",
    "                if \"exog_vars_base\" in config:\n",
    "                    for dummy_name in config[\"exog_vars_base\"]:\n",
    "                        if dummy_name == \"d_outlier_2022_01_1m\":\n",
    "                            exog_list.append(self._create_pulse_dummy(\n",
    "                                self.all_series_data.index, '2022-01-01', 1, dummy_name\n",
    "                            ))\n",
    "                        elif dummy_name == \"d_outlier_2022_10_1m\":\n",
    "                            exog_list.append(self._create_pulse_dummy(\n",
    "                                self.all_series_data.index, '2022-10-01', 1, dummy_name\n",
    "                            ))\n",
    "                \n",
    "                # Variabili Google Trends con lag\n",
    "                if \"gt_vars_lags\" in config:\n",
    "                    for gt_col, lag in config[\"gt_vars_lags\"].items():\n",
    "                        if gt_col in self.all_series_data.columns:\n",
    "                            lagged_series = self.all_series_data[gt_col].shift(lag)\n",
    "                            lagged_series.name = f\"{gt_col}_lag{lag}\"\n",
    "                            exog_list.append(lagged_series)\n",
    "                \n",
    "                # Combinazione finale\n",
    "                if exog_list:\n",
    "                    exog_df = pd.concat(exog_list, axis=1).astype(float)\n",
    "                    # Rimozione duplicati se presenti\n",
    "                    if exog_df.index.duplicated().any():\n",
    "                        exog_df = exog_df[~exog_df.index.duplicated(keep='last')]\n",
    "                    self.exog_data_prepared[model_name] = exog_df.reindex(self.all_series_data.index)\n",
    "                    n_vars = len(exog_list)\n",
    "                    print(f\"   â€¢ {model_name}: {n_vars} variabili esogene\")\n",
    "                else:\n",
    "                    self.exog_data_prepared[model_name] = None\n",
    "                    print(f\"   â€¢ {model_name}: nessuna variabile esogene\")\n",
    "                    \n",
    "            print(\"\\nPreparazione dati completata con successo\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nErrore critico nel caricamento dati: {e}\")\n",
    "            return False\n",
    "\n",
    "    def _forecast_single_model_oos(self, y_series: pd.Series, exog_series: Optional[pd.DataFrame],\n",
    "                                  order: Tuple, seasonal_order: Tuple, model_name: str) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Genera previsioni OOS per un singolo modello.\n",
    "        Come simulare trading in tempo reale usando solo info disponibili al momento.\n",
    "        \"\"\"\n",
    "        forecasts_by_h = {h: [] for h in self.config.ORIZZONTI_PREVISIONE}\n",
    "        n_obs = len(y_series)\n",
    "        max_h = max(self.config.ORIZZONTI_PREVISIONE)\n",
    "        n_iterations = n_obs - self.config.LUNGHEZZA_FINESTRA_INIZIALE - max_h + 1\n",
    "        \n",
    "        if n_iterations <= 0:\n",
    "            return None\n",
    "            \n",
    "        print(f\"   â†’ Esecuzione {n_iterations} iterazioni di forecasting...\")\n",
    "        successful_iters = 0\n",
    "        \n",
    "        # Progress tracking\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i in range(n_iterations):\n",
    "            try:\n",
    "                # Definizione finestra training (rolling vs recursive)\n",
    "                if self.config.SCHEMA_PREVISIONE == 'rolling':\n",
    "                    train_start = i\n",
    "                    train_end = i + self.config.LUNGHEZZA_FINESTRA_INIZIALE - 1\n",
    "                else:  # recursive\n",
    "                    train_start = 0\n",
    "                    train_end = self.config.LUNGHEZZA_FINESTRA_INIZIALE + i - 1\n",
    "                \n",
    "                # Estrazione dati training\n",
    "                y_train = y_series.iloc[train_start:train_end + 1]\n",
    "                exog_train = exog_series.iloc[train_start:train_end + 1] if exog_series is not None else None\n",
    "                \n",
    "                # Stima modello\n",
    "                model = sm.tsa.SARIMAX(\n",
    "                    y_train, exog=exog_train, order=order, seasonal_order=seasonal_order,\n",
    "                    enforce_stationarity=False, enforce_invertibility=False,\n",
    "                    initialization='approximate_diffuse'\n",
    "                )\n",
    "                fitted = model.fit(disp=False, maxiter=200, method='lbfgs')\n",
    "                \n",
    "                # Previsioni per ogni orizzonte\n",
    "                for h in self.config.ORIZZONTI_PREVISIONE:\n",
    "                    # Preparazione esogene future\n",
    "                    if exog_series is not None:\n",
    "                        exog_start = train_end + 1\n",
    "                        exog_end = train_end + h\n",
    "                        if exog_end < n_obs:\n",
    "                            exog_forecast = exog_series.iloc[exog_start:exog_end + 1]\n",
    "                            if len(exog_forecast) != h:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        exog_forecast = None\n",
    "                    \n",
    "                    # Generazione previsione\n",
    "                    forecast = fitted.get_forecast(steps=h, exog=exog_forecast)\n",
    "                    forecast_value = forecast.predicted_mean.iloc[-1]\n",
    "                    \n",
    "                    # Valore osservato\n",
    "                    actual_idx = train_end + h\n",
    "                    if actual_idx < n_obs:\n",
    "                        forecasts_by_h[h].append({\n",
    "                            'date': y_series.index[actual_idx],\n",
    "                            'actual': y_series.iloc[actual_idx],\n",
    "                            'forecast': forecast_value\n",
    "                        })\n",
    "                \n",
    "                successful_iters += 1\n",
    "                \n",
    "                # Progress update\n",
    "                if (i + 1) % 10 == 0:\n",
    "                    progress = (i + 1) / n_iterations * 100\n",
    "                    elapsed = time.time() - start_time\n",
    "                    eta = elapsed / (i + 1) * (n_iterations - i - 1)\n",
    "                    print(f\"      Progresso: {progress:.1f}% - ETA: {eta:.0f}s\", end='\\r')\n",
    "                    \n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\n      âœ“ Completate {successful_iters}/{n_iterations} iterazioni\")\n",
    "        \n",
    "        # Conversione a DataFrame con gestione duplicati\n",
    "        forecast_dfs = {}\n",
    "        for h, preds_list in forecasts_by_h.items():\n",
    "            if preds_list:\n",
    "                df = pd.DataFrame(preds_list)\n",
    "                # CORREZIONE: Rimozione duplicati prima di set_index\n",
    "                if df['date'].duplicated().any():\n",
    "                    df = df.drop_duplicates(subset=['date'], keep='last')\n",
    "                forecast_dfs[h] = df.set_index('date')\n",
    "                \n",
    "        return forecast_dfs if forecast_dfs else None\n",
    "\n",
    "    def generate_all_oos_forecasts(self) -> bool:\n",
    "        \"\"\"Genera tutte le previsioni OOS per tutti i modelli\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FASE 2: GENERAZIONE PREVISIONI OUT-OF-SAMPLE\")\n",
    "        print(f\"   Schema: {self.config.SCHEMA_PREVISIONE} | Finestra: {self.config.LUNGHEZZA_FINESTRA_INIZIALE} mesi\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for model_name, model_config in self.config.MODELLI_DA_TESTARE.items():\n",
    "            print(f\"\\nðŸ“Š Modello: {model_name}\")\n",
    "            print(f\"   SARIMA{model_config['order']}{model_config['seasonal_order']}\")\n",
    "            \n",
    "            # Preparazione dati allineati per il modello\n",
    "            exog = self.exog_data_prepared.get(model_name)\n",
    "            if exog is not None:\n",
    "                # Allineamento e rimozione NA\n",
    "                combined = pd.concat([self.target_series_clean, exog], axis=1)\n",
    "                combined_clean = combined.dropna()\n",
    "                y_model = combined_clean.iloc[:, 0]\n",
    "                exog_model = combined_clean.iloc[:, 1:]\n",
    "            else:\n",
    "                y_model = self.target_series_clean.copy()\n",
    "                exog_model = None\n",
    "            \n",
    "            # Verifica dati sufficienti\n",
    "            min_obs = self.config.LUNGHEZZA_FINESTRA_INIZIALE + max(self.config.ORIZZONTI_PREVISIONE)\n",
    "            if len(y_model) < min_obs:\n",
    "                print(f\"     Dati insufficienti: {len(y_model)} obs (min richieste: {min_obs})\")\n",
    "                continue\n",
    "            \n",
    "            # Generazione previsioni\n",
    "            forecasts = self._forecast_single_model_oos(\n",
    "                y_model, exog_model,\n",
    "                model_config['order'], model_config['seasonal_order'],\n",
    "                model_name\n",
    "            )\n",
    "            \n",
    "            if forecasts:\n",
    "                self.all_forecast_results[model_name] = forecasts\n",
    "                # Report previsioni generate\n",
    "                for h, df in forecasts.items():\n",
    "                    print(f\"   â€¢ h={h}: {len(df)} previsioni generate\")\n",
    "            else:\n",
    "                print(f\"    Nessuna previsione generata\")\n",
    "        \n",
    "        success = bool(self.all_forecast_results)\n",
    "        if success:\n",
    "            print(f\"\\nPrevisioni completate per {len(self.all_forecast_results)} modelli\")\n",
    "        else:\n",
    "            print(\"\\nNessuna previsione generata con successo\")\n",
    "            \n",
    "        return success\n",
    "\n",
    "    def calculate_and_store_forecast_metrics(self) -> bool:\n",
    "        \"\"\"Calcola metriche di accuratezza delle previsioni\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FASE 3: CALCOLO METRICHE DI ACCURATEZZA\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        self.results_metrics = []\n",
    "        \n",
    "        for model_name, forecasts_by_h in self.all_forecast_results.items():\n",
    "            for h, forecast_df in forecasts_by_h.items():\n",
    "                if forecast_df is not None and len(forecast_df) >= self.config.MIN_OBS_FORECAST_TESTS // 2:\n",
    "                    actual = forecast_df['actual'].values\n",
    "                    forecast = forecast_df['forecast'].values\n",
    "                    \n",
    "                    # Calcolo metriche\n",
    "                    rmse = np.sqrt(mean_squared_error(actual, forecast))\n",
    "                    mae = mean_absolute_error(actual, forecast)\n",
    "                    mape = np.mean(np.abs((actual - forecast) / np.where(np.abs(actual) < 1e-9, 1e-9, actual))) * 100\n",
    "                    \n",
    "                    # Direzione corretta\n",
    "                    direction_accuracy = np.mean(np.sign(actual) == np.sign(forecast)) * 100\n",
    "                    \n",
    "                    self.results_metrics.append({\n",
    "                        'Modello': model_name,\n",
    "                        'Orizzonte': h,\n",
    "                        'RMSE': rmse,\n",
    "                        'MAE': mae,\n",
    "                        'MAPE': mape,\n",
    "                        'Dir_Accuracy': direction_accuracy,\n",
    "                        'N_Obs': len(forecast_df)\n",
    "                    })\n",
    "        \n",
    "        if not self.results_metrics:\n",
    "            print(\"Nessuna metrica calcolata\")\n",
    "            return False\n",
    "        \n",
    "        # Salvataggio metriche\n",
    "        df_metrics = pd.DataFrame(self.results_metrics)\n",
    "        metrics_file = os.path.join(self.config.PATH_OUTPUT_OOS, f\"metriche_oos_{self.config.SCHEMA_PREVISIONE}.csv\")\n",
    "        df_metrics.to_csv(metrics_file, index=False)\n",
    "        \n",
    "        # Visualizzazione tabella formattata\n",
    "        print(\"\\nTabella Riepilogativa Metriche:\")\n",
    "        pivot_rmse = df_metrics.pivot(index='Modello', columns='Orizzonte', values='RMSE')\n",
    "        pivot_mae = df_metrics.pivot(index='Modello', columns='Orizzonte', values='MAE')\n",
    "        \n",
    "        print(\"\\nRMSE per Orizzonte:\")\n",
    "        print(tabulate(pivot_rmse.round(4), headers='keys', tablefmt='grid'))\n",
    "        \n",
    "        print(\"\\nMAE per Orizzonte:\")\n",
    "        print(tabulate(pivot_mae.round(4), headers='keys', tablefmt='grid'))\n",
    "        \n",
    "        # Identificazione migliori modelli\n",
    "        print(\"\\nMigliori Modelli per Orizzonte:\")\n",
    "        for h in self.config.ORIZZONTI_PREVISIONE:\n",
    "            h_data = df_metrics[df_metrics['Orizzonte'] == h]\n",
    "            if not h_data.empty:\n",
    "                best_rmse = h_data.loc[h_data['RMSE'].idxmin()]\n",
    "                print(f\"   h={h}: {best_rmse['Modello']} (RMSE={best_rmse['RMSE']:.4f})\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def _get_aligned_forecasts(self, model1: str, model2: str, horizon: int) -> Tuple[Optional[np.ndarray], ...]:\n",
    "        \"\"\"Allinea previsioni di due modelli per confronto\"\"\"\n",
    "        if not all([\n",
    "            model1 in self.all_forecast_results,\n",
    "            model2 in self.all_forecast_results,\n",
    "            horizon in self.all_forecast_results[model1],\n",
    "            horizon in self.all_forecast_results[model2]\n",
    "        ]):\n",
    "            return None, None, None\n",
    "            \n",
    "        df1 = self.all_forecast_results[model1][horizon]\n",
    "        df2 = self.all_forecast_results[model2][horizon]\n",
    "        \n",
    "        # Trova date comuni senza duplicati\n",
    "        common_dates = df1.index.intersection(df2.index)\n",
    "        common_dates = common_dates[~common_dates.duplicated()]\n",
    "        \n",
    "        if len(common_dates) < self.config.MIN_OBS_FORECAST_TESTS:\n",
    "            return None, None, None\n",
    "            \n",
    "        # Estrai valori allineati\n",
    "        actual = df1.loc[common_dates, 'actual'].values\n",
    "        pred1 = df1.loc[common_dates, 'forecast'].values\n",
    "        pred2 = df2.loc[common_dates, 'forecast'].values\n",
    "        \n",
    "        return actual, pred1, pred2\n",
    "\n",
    "    def perform_advanced_forecast_tests(self) -> bool:\n",
    "        \"\"\"Esegue test statistici avanzati\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FASE 4: TEST STATISTICI AVANZATI\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        dm_results = []\n",
    "        cw_results = []\n",
    "        enc_results = []\n",
    "        spa_results = []\n",
    "        \n",
    "        model_names = list(self.all_forecast_results.keys())\n",
    "        benchmark_model = \"Base_Outliers\"\n",
    "        \n",
    "        for h in self.config.ORIZZONTI_PREVISIONE:\n",
    "            print(f\"\\nOrizzonte h={h}:\")\n",
    "            \n",
    "            # Preparazione dati per SPA test\n",
    "            predictions_dict = {}\n",
    "            actual_values = None\n",
    "            \n",
    "            for model in model_names:\n",
    "                if h in self.all_forecast_results[model]:\n",
    "                    df = self.all_forecast_results[model][h]\n",
    "                    if len(df) >= self.config.MIN_OBS_FORECAST_TESTS:\n",
    "                        if actual_values is None:\n",
    "                            actual_values = df['actual']\n",
    "                            common_idx = df.index\n",
    "                        else:\n",
    "                            # Trova indice comune senza duplicati\n",
    "                            common_idx = common_idx.intersection(df.index)\n",
    "                            common_idx = common_idx[~common_idx.duplicated()]\n",
    "                        \n",
    "                        if len(common_idx) >= self.config.MIN_OBS_FORECAST_TESTS:\n",
    "                            predictions_dict[model] = df.loc[common_idx, 'forecast']\n",
    "            \n",
    "            # SPA Test se abbiamo dati sufficienti\n",
    "            if len(predictions_dict) > 1 and benchmark_model in predictions_dict:\n",
    "                actual_spa = actual_values.loc[common_idx].values\n",
    "                preds_spa = {k: v.values for k, v in predictions_dict.items()}\n",
    "                \n",
    "                spa_stat, spa_pval, spa_diffs = spa_test(\n",
    "                    actual_spa, preds_spa, benchmark_model, \n",
    "                    n_bootstrap=self.config.N_BOOTSTRAP_SPA\n",
    "                )\n",
    "                \n",
    "                if not np.isnan(spa_stat):\n",
    "                    spa_results.append({\n",
    "                        'Orizzonte': h,\n",
    "                        'Benchmark': benchmark_model,\n",
    "                        'SPA_Stat': spa_stat,\n",
    "                        'P_Value': spa_pval,\n",
    "                        'Significativo': spa_pval < self.config.ALPHA_LEVEL\n",
    "                    })\n",
    "                    sig_text = \" Significativo\" if spa_pval < self.config.ALPHA_LEVEL else \"\"\n",
    "                    print(f\"    SPA Test: stat={spa_stat:.4f}, p-value={spa_pval:.4f} {sig_text}\")\n",
    "            \n",
    "            # Test a coppie\n",
    "            for model1, model2 in combinations(model_names, 2):\n",
    "                actual_aligned, pred1, pred2 = self._get_aligned_forecasts(model1, model2, h)\n",
    "                \n",
    "                if actual_aligned is None:\n",
    "                    continue\n",
    "                \n",
    "                # Diebold-Mariano Test\n",
    "                try:\n",
    "                    dm_stat, dm_pval = dm_test(actual_aligned, pred1, pred2, h=h)\n",
    "                    dm_results.append({\n",
    "                        'Orizzonte': h,\n",
    "                        'Modello_1': model1,\n",
    "                        'Modello_2': model2,\n",
    "                        'DM_Stat': dm_stat,\n",
    "                        'P_Value': dm_pval,\n",
    "                        'Significativo': dm_pval < self.config.ALPHA_LEVEL,\n",
    "                        'N_Obs': len(actual_aligned)\n",
    "                    })\n",
    "                except Exception:\n",
    "                    pass\n",
    "                \n",
    "                # Clark-West Test (solo se model1 Ã¨ nested in model2)\n",
    "                if model1 == benchmark_model:\n",
    "                    cw_stat, cw_pval = clark_west_test(actual_aligned, pred1, pred2, horizon=h)\n",
    "                    if not np.isnan(cw_stat):\n",
    "                        cw_results.append({\n",
    "                            'Orizzonte': h,\n",
    "                            'Modello_Base': model1,\n",
    "                            'Modello_Esteso': model2,\n",
    "                            'CW_Stat': cw_stat,\n",
    "                            'P_Value': cw_pval,\n",
    "                            'Significativo': cw_pval < self.config.ALPHA_LEVEL\n",
    "                        })\n",
    "                \n",
    "                # Encompassing Test\n",
    "                enc_t, enc_p, enc_beta = encompassing_test(actual_aligned, pred1, pred2)\n",
    "                if not np.isnan(enc_t):\n",
    "                    enc_results.append({\n",
    "                        'Orizzonte': h,\n",
    "                        'Modello_1': model1,\n",
    "                        'Modello_2': model2,\n",
    "                        'Beta': enc_beta,\n",
    "                        'T_Stat': enc_t,\n",
    "                        'P_Value': enc_p,\n",
    "                        'M1_Ingloba_M2': enc_p >= self.config.ALPHA_LEVEL\n",
    "                    })\n",
    "        \n",
    "        # Salvataggio risultati\n",
    "        base_path = self.config.PATH_OUTPUT_OOS\n",
    "        \n",
    "        if dm_results:\n",
    "            pd.DataFrame(dm_results).to_csv(\n",
    "                os.path.join(base_path, f\"test_diebold_mariano_{self.config.SCHEMA_PREVISIONE}.csv\"),\n",
    "                index=False\n",
    "            )\n",
    "            print(f\"\\nSalvati {len(dm_results)} test Diebold-Mariano\")\n",
    "        \n",
    "        if cw_results:\n",
    "            pd.DataFrame(cw_results).to_csv(\n",
    "                os.path.join(base_path, f\"test_clark_west_{self.config.SCHEMA_PREVISIONE}.csv\"),\n",
    "                index=False\n",
    "            )\n",
    "            print(f\"Salvati {len(cw_results)} test Clark-West\")\n",
    "        \n",
    "        if enc_results:\n",
    "            pd.DataFrame(enc_results).to_csv(\n",
    "                os.path.join(base_path, f\"test_encompassing_{self.config.SCHEMA_PREVISIONE}.csv\"),\n",
    "                index=False\n",
    "            )\n",
    "            print(f\"Salvati {len(enc_results)} test Encompassing\")\n",
    "        \n",
    "        if spa_results:\n",
    "            pd.DataFrame(spa_results).to_csv(\n",
    "                os.path.join(base_path, f\"test_spa_{self.config.SCHEMA_PREVISIONE}.csv\"),\n",
    "                index=False\n",
    "            )\n",
    "            print(f\"Salvati {len(spa_results)} test SPA\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def generate_final_report_and_plots(self) -> bool:\n",
    "        \"\"\"Genera report finale e visualizzazioni\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FASE 5: GENERAZIONE REPORT E GRAFICI\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if not self.results_metrics:\n",
    "            print(\"Nessuna metrica disponibile per il report\")\n",
    "            return False\n",
    "        \n",
    "        df_metrics = pd.DataFrame(self.results_metrics)\n",
    "        \n",
    "        # Configurazione stile grafici\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        colors = sns.color_palette(\"husl\", len(df_metrics['Modello'].unique()))\n",
    "        \n",
    "        # 1. Grafico RMSE per orizzonte\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        for i, model in enumerate(df_metrics['Modello'].unique()):\n",
    "            model_data = df_metrics[df_metrics['Modello'] == model]\n",
    "            ax1.plot(model_data['Orizzonte'], model_data['RMSE'], \n",
    "                    marker='o', linewidth=2.5, markersize=8, \n",
    "                    label=model, color=colors[i])\n",
    "            ax2.plot(model_data['Orizzonte'], model_data['MAE'], \n",
    "                    marker='s', linewidth=2.5, markersize=8, \n",
    "                    label=model, color=colors[i])\n",
    "        \n",
    "        ax1.set_xlabel('Orizzonte di Previsione (mesi)', fontsize=12)\n",
    "        ax1.set_ylabel('RMSE', fontsize=12)\n",
    "        ax1.set_title('Root Mean Squared Error per Orizzonte', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xticks(self.config.ORIZZONTI_PREVISIONE)\n",
    "        ax1.legend(loc='best', framealpha=0.9)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax2.set_xlabel('Orizzonte di Previsione (mesi)', fontsize=12)\n",
    "        ax2.set_ylabel('MAE', fontsize=12)\n",
    "        ax2.set_title('Mean Absolute Error per Orizzonte', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xticks(self.config.ORIZZONTI_PREVISIONE)\n",
    "        ax2.legend(loc='best', framealpha=0.9)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        metrics_plot = os.path.join(self.config.PATH_OUTPUT_OOS, f\"metriche_confronto_{self.config.SCHEMA_PREVISIONE}.png\")\n",
    "        plt.savefig(metrics_plot, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Grafico metriche salvato: {os.path.basename(metrics_plot)}\")\n",
    "        \n",
    "        # 2. Heatmap delle performance relative\n",
    "        pivot_rmse = df_metrics.pivot(index='Modello', columns='Orizzonte', values='RMSE')\n",
    "        \n",
    "        # Calcolo performance relativa rispetto al benchmark\n",
    "        if 'Base_Outliers' in pivot_rmse.index:\n",
    "            relative_perf = (pivot_rmse - pivot_rmse.loc['Base_Outliers']) / pivot_rmse.loc['Base_Outliers'] * 100\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.heatmap(relative_perf, annot=True, fmt='.1f', cmap='RdYlGn_r', center=0,\n",
    "                       cbar_kws={'label': 'Performance Relativa (%)'})\n",
    "            plt.title('Performance Relativa vs Modello Base (RMSE)', fontsize=14, fontweight='bold')\n",
    "            plt.ylabel('Modello', fontsize=12)\n",
    "            plt.xlabel('Orizzonte (mesi)', fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            heatmap_plot = os.path.join(self.config.PATH_OUTPUT_OOS, f\"heatmap_performance_{self.config.SCHEMA_PREVISIONE}.png\")\n",
    "            plt.savefig(heatmap_plot, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Heatmap performance salvata: {os.path.basename(heatmap_plot)}\")\n",
    "        \n",
    "        # 3. Grafico accuratezza direzionale\n",
    "        if 'Dir_Accuracy' in df_metrics.columns:\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            \n",
    "            pivot_dir = df_metrics.pivot(index='Modello', columns='Orizzonte', values='Dir_Accuracy')\n",
    "            x = np.arange(len(self.config.ORIZZONTI_PREVISIONE))\n",
    "            width = 0.2\n",
    "            \n",
    "            for i, model in enumerate(pivot_dir.index):\n",
    "                offset = (i - len(pivot_dir.index)/2 + 0.5) * width\n",
    "                ax.bar(x + offset, pivot_dir.loc[model], width, \n",
    "                      label=model, alpha=0.8)\n",
    "            \n",
    "            ax.set_xlabel('Orizzonte di Previsione (mesi)', fontsize=12)\n",
    "            ax.set_ylabel('Accuratezza Direzionale (%)', fontsize=12)\n",
    "            ax.set_title('Accuratezza nella Previsione della Direzione', fontsize=14, fontweight='bold')\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels(self.config.ORIZZONTI_PREVISIONE)\n",
    "            ax.legend(loc='best')\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "            ax.set_ylim(0, 100)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            dir_plot = os.path.join(self.config.PATH_OUTPUT_OOS, f\"accuratezza_direzionale_{self.config.SCHEMA_PREVISIONE}.png\")\n",
    "            plt.savefig(dir_plot, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Grafico accuratezza direzionale salvato: {os.path.basename(dir_plot)}\")\n",
    "        \n",
    "        # 4. Report testuale riassuntivo\n",
    "        report_lines = []\n",
    "        report_lines.append(\"=\"*60)\n",
    "        report_lines.append(\"REPORT FINALE ANALISI OUT-OF-SAMPLE\")\n",
    "        report_lines.append(\"=\"*60)\n",
    "        report_lines.append(f\"\\nData Analisi: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "        report_lines.append(f\"Schema Previsione: {self.config.SCHEMA_PREVISIONE}\")\n",
    "        report_lines.append(f\"Finestra Iniziale: {self.config.LUNGHEZZA_FINESTRA_INIZIALE} mesi\")\n",
    "        report_lines.append(f\"Orizzonti Testati: {self.config.ORIZZONTI_PREVISIONE}\")\n",
    "        report_lines.append(f\"Modelli Analizzati: {len(self.config.MODELLI_DA_TESTARE)}\")\n",
    "        \n",
    "        report_lines.append(\"\\n\" + \"-\"*40)\n",
    "        report_lines.append(\"MIGLIORI MODELLI PER ORIZZONTE (RMSE)\")\n",
    "        report_lines.append(\"-\"*40)\n",
    "        \n",
    "        for h in self.config.ORIZZONTI_PREVISIONE:\n",
    "            h_data = df_metrics[df_metrics['Orizzonte'] == h]\n",
    "            if not h_data.empty:\n",
    "                best = h_data.loc[h_data['RMSE'].idxmin()]\n",
    "                report_lines.append(f\"h={h:2d}: {best['Modello']:20s} RMSE={best['RMSE']:.4f} MAE={best['MAE']:.4f}\")\n",
    "        \n",
    "        # Salva report\n",
    "        report_file = os.path.join(self.config.PATH_OUTPUT_OOS, f\"report_finale_{self.config.SCHEMA_PREVISIONE}.txt\")\n",
    "        with open(report_file, 'w') as f:\n",
    "            f.write('\\n'.join(report_lines))\n",
    "        \n",
    "        print(f\"\\nReport testuale salvato: {os.path.basename(report_file)}\")\n",
    "        \n",
    "        # 5. Configurazione esperimento in JSON\n",
    "        config_summary = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'configurazione': {\n",
    "                'schema_previsione': self.config.SCHEMA_PREVISIONE,\n",
    "                'finestra_iniziale': self.config.LUNGHEZZA_FINESTRA_INIZIALE,\n",
    "                'orizzonti': self.config.ORIZZONTI_PREVISIONE,\n",
    "                'alpha_level': self.config.ALPHA_LEVEL,\n",
    "                'n_bootstrap_spa': self.config.N_BOOTSTRAP_SPA\n",
    "            },\n",
    "            'modelli': self.config.MODELLI_DA_TESTARE,\n",
    "            'risultati_summary': {\n",
    "                'n_modelli_testati': len(self.all_forecast_results),\n",
    "                'n_metriche_calcolate': len(self.results_metrics)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        config_file = os.path.join(self.config.PATH_OUTPUT_OOS, \"configurazione_esperimento.json\")\n",
    "        with open(config_file, 'w') as f:\n",
    "            json.dump(config_summary, f, indent=4)\n",
    "        \n",
    "        print(f\"Configurazione salvata: {os.path.basename(config_file)}\")\n",
    "        print(\"\\nReport e grafici completati con successo!\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def run_complete_analysis(self) -> bool:\n",
    "        \"\"\"Esegue l'analisi completa\"\"\"\n",
    "        print(\"\\n\" + \"=\"*20)\n",
    "        print(\"ANALISI OUT-OF-SAMPLE PROFESSIONALE\")\n",
    "        print(\"Framework per Valutazione Modelli di Forecasting\")\n",
    "        print(\"=\"*20)\n",
    "        \n",
    "        try:\n",
    "            # Fase 1: Caricamento dati\n",
    "            if not self.load_and_prepare_data():\n",
    "                return False\n",
    "            \n",
    "            # Fase 2: Generazione previsioni\n",
    "            if not self.generate_all_oos_forecasts():\n",
    "                return False\n",
    "            \n",
    "            # Fase 3: Calcolo metriche\n",
    "            if not self.calculate_and_store_forecast_metrics():\n",
    "                return False\n",
    "            \n",
    "            # Fase 4: Test statistici\n",
    "            self.perform_advanced_forecast_tests()\n",
    "            \n",
    "            # Fase 5: Report finale\n",
    "            self.generate_final_report_and_plots()\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"ANALISI COMPLETATA CON SUCCESSO!\")\n",
    "            print(f\"Tutti i risultati salvati in: {self.config.PATH_OUTPUT_OOS}\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nErrore critico: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "\n",
    "\n",
    "# ==================== ESECUZIONE PRINCIPALE ====================\n",
    "def main():\n",
    "    \"\"\"Funzione principale\"\"\"\n",
    "    try:\n",
    "        # Inizializzazione\n",
    "        config = Config()\n",
    "        framework = ForecastingFramework(config)\n",
    "        \n",
    "        # Esecuzione analisi\n",
    "        start_time = time.time()\n",
    "        success = framework.run_complete_analysis()\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        if success:\n",
    "            print(f\"\\nTempo totale di esecuzione: {elapsed_time:.1f} secondi\")\n",
    "        else:\n",
    "            print(\"\\nAnalisi terminata con errori\")\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nEsecuzione interrotta dall'utente\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nErrore fatale: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_python_env)",
   "language": "python",
   "name": "my_python_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
