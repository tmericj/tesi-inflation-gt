{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894d212b",
   "metadata": {},
   "source": [
    "# MIDAS for GT indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5b5f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting midaspy\n",
      "  Downloading MIDASpy-1.2.3-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy>=1.5 in /Users/tommaso/my_python_env/lib/python3.13/site-packages (from midaspy) (2.2.5)\n",
      "Requirement already satisfied: scikit-learn in /Users/tommaso/my_python_env/lib/python3.13/site-packages (from midaspy) (1.6.1)\n",
      "Requirement already satisfied: matplotlib in /Users/tommaso/my_python_env/lib/python3.13/site-packages (from midaspy) (3.10.1)\n",
      "Requirement already satisfied: pandas>=0.19 in /Users/tommaso/my_python_env/lib/python3.13/site-packages (from midaspy) (2.2.3)\n",
      "INFO: pip is looking at multiple versions of midaspy to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading MIDASpy-1.2.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading MIDASpy-1.2.1.tar.gz (21 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading MIDASpy-1.2.0.tar.gz (21 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading MIDASpy-1.1.1-py3-none-any.whl.metadata (1.0 kB)\n",
      "  Downloading MIDASpy-1.1.0.tar.gz (19 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading MIDASpy-1.0.2.tar.gz (18 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[31mERROR: Cannot install midaspy==1.0.2, midaspy==1.1.0, midaspy==1.1.1, midaspy==1.2.0, midaspy==1.2.1, midaspy==1.2.2 and midaspy==1.2.3 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "The conflict is caused by:\n",
      "    midaspy 1.2.3 depends on tensorflow-addons>=0.11\n",
      "    midaspy 1.2.2 depends on tensorflow>=1.10\n",
      "    midaspy 1.2.1 depends on tensorflow>=1.10\n",
      "    midaspy 1.2.0 depends on tensorflow>=1.10\n",
      "    midaspy 1.1.1 depends on tensorflow>=1.10\n",
      "    midaspy 1.1.0 depends on tensorflow>=1.10\n",
      "    midaspy 1.0.2 depends on tensorflow>=1.10\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install midaspy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d873c09",
   "metadata": {},
   "source": [
    "### Step 1: Import librerie e caricamento tutti i dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eecef871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup librerie completato ✓\n",
      "Caricamento dati...\n",
      "Tutti i dati caricati:\n",
      "Compensation shape: (81, 2)\n",
      "GDP Nominal shape: (79, 2)\n",
      "GT monthly shape: (252, 12)\n",
      "NIC monthly shape: (252, 2)\n",
      "\n",
      "Struttura files:\n",
      "Compensation: ['observation_date', 'ITACOMPQDSNAQ']\n",
      "GDP: ['observation_date', 'ITAGDPNQDSMEI']\n",
      "GT: ['Unnamed: 0', 'indice_Inflazione_GT_PCA_SA', 'indice_Tematico_GT_SA', 'indice_Termini_Diretti_Purificato', 'indice_Alimentari_Purificato']\n",
      "NIC: ['Periodo', 'NIC_destag_ISTAT']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import beta as beta_func\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Setup librerie completato ✓\")\n",
    "\n",
    "# Caricamento tutti i dati necessari\n",
    "print(\"Caricamento dati...\")\n",
    "\n",
    "# 1. Dati FRED\n",
    "compensation = pd.read_csv('/Users/tommaso/Desktop/tesi-inflation-gt/HNKPC/FRED_data/ITACOMPQDSNAQ.csv')\n",
    "gdp_nominal = pd.read_csv('/Users/tommaso/Desktop/tesi-inflation-gt/HNKPC/FRED_data/ITAGDPNQDSMEI.csv')\n",
    "\n",
    "# 2. GT monthly destagionalizzati\n",
    "gt_monthly = pd.read_csv('/Users/tommaso/Desktop/tesi-inflation-gt/Destagionalized_Indexes/dati_preparati_fase1/indici_gt_destag_fase1.csv')\n",
    "\n",
    "# 3. NIC monthly destagionalizzato\n",
    "nic_monthly = pd.read_csv('/Users/tommaso/Desktop/tesi-inflation-gt/Destagionalized_Indexes/dati_preparati_fase1/nic_fase1.csv')\n",
    "\n",
    "print(\"Tutti i dati caricati:\")\n",
    "print(f\"Compensation shape: {compensation.shape}\")\n",
    "print(f\"GDP Nominal shape: {gdp_nominal.shape}\")\n",
    "print(f\"GT monthly shape: {gt_monthly.shape}\")\n",
    "print(f\"NIC monthly shape: {nic_monthly.shape}\")\n",
    "\n",
    "# Mostra strutture per verificare\n",
    "print(\"\\nStruttura files:\")\n",
    "print(\"Compensation:\", compensation.columns.tolist())\n",
    "print(\"GDP:\", gdp_nominal.columns.tolist())\n",
    "print(\"GT:\", gt_monthly.columns.tolist()[:5])  # Prime 5 colonne\n",
    "print(\"NIC:\", nic_monthly.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74aa10d",
   "metadata": {},
   "source": [
    "### Step 2: Preparazione dati FRED e calcolo Labor Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6095983c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labor Share calcolata:\n",
      "Osservazioni FRED: 79\n",
      "Periodo: da 2004-01-01 00:00:00 a 2023-07-01 00:00:00\n",
      "Labor Share - Media: 39.46%\n",
      "Labor Share - Range: 37.40% - 41.21%\n",
      "\n",
      "Sample Labor Share:\n",
      "        DATE  LABOR_SHARE\n",
      "0 2004-01-01    37.395267\n",
      "1 2004-04-01    37.742574\n",
      "2 2004-07-01    37.624326\n",
      "3 2004-10-01    37.526931\n",
      "4 2005-01-01    38.039639\n"
     ]
    }
   ],
   "source": [
    "# Prepara dati FRED\n",
    "compensation.columns = ['DATE', 'COMPENSATION']\n",
    "gdp_nominal.columns = ['DATE', 'GDP_NOMINAL']\n",
    "\n",
    "# Converti date\n",
    "compensation['DATE'] = pd.to_datetime(compensation['DATE'])\n",
    "gdp_nominal['DATE'] = pd.to_datetime(gdp_nominal['DATE'])\n",
    "\n",
    "# Definisci periodo comune\n",
    "start_date = '2004-01-01'\n",
    "end_date = '2023-09-30'\n",
    "\n",
    "# Filtra FRED data\n",
    "compensation_filtered = compensation[\n",
    "    (compensation['DATE'] >= start_date) & \n",
    "    (compensation['DATE'] <= end_date)\n",
    "].copy()\n",
    "\n",
    "gdp_filtered = gdp_nominal[\n",
    "    (gdp_nominal['DATE'] >= start_date) & \n",
    "    (gdp_nominal['DATE'] <= end_date)\n",
    "].copy()\n",
    "\n",
    "# Merge e calcolo Labor Share\n",
    "fred_data = pd.merge(compensation_filtered, gdp_filtered, on='DATE', how='inner')\n",
    "fred_data['LABOR_SHARE'] = (fred_data['COMPENSATION'] / fred_data['GDP_NOMINAL']) * 100\n",
    "\n",
    "# Crea mapping quarterly\n",
    "fred_data['YEAR_QUARTER'] = fred_data['DATE'].dt.to_period('Q')\n",
    "\n",
    "print(\"Labor Share calcolata:\")\n",
    "print(f\"Osservazioni FRED: {fred_data.shape[0]}\")\n",
    "print(f\"Periodo: da {fred_data['DATE'].min()} a {fred_data['DATE'].max()}\")\n",
    "print(f\"Labor Share - Media: {fred_data['LABOR_SHARE'].mean():.2f}%\")\n",
    "print(f\"Labor Share - Range: {fred_data['LABOR_SHARE'].min():.2f}% - {fred_data['LABOR_SHARE'].max():.2f}%\")\n",
    "\n",
    "# Mostra sample\n",
    "print(\"\\nSample Labor Share:\")\n",
    "print(fred_data[['DATE', 'LABOR_SHARE']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c17353",
   "metadata": {},
   "source": [
    "### Step 3: Preparazione dati GT monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07be3d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne GT disponibili:\n",
      "0: Unnamed: 0\n",
      "1: indice_Inflazione_GT_PCA_SA\n",
      "2: indice_Tematico_GT_SA\n",
      "3: indice_Termini_Diretti_Purificato\n",
      "4: indice_Alimentari_Purificato\n",
      "5: indice_Energia_Purificato\n",
      "6: indice_Abitazione_Purificato\n",
      "7: indice_Trasporti_Purificato\n",
      "8: indice_Politiche_Economiche_Purificato\n",
      "9: indice_Aspettative_Consumatori_Purificato\n",
      "10: indice_Sanita_Purificato\n",
      "11: indice_Ricreazione_Purificato\n",
      "Colonne GT selezionate: ['indice_Inflazione_GT_PCA_SA', 'indice_Tematico_GT_SA']\n",
      "\n",
      "GT monthly preparati: 237 osservazioni\n",
      "Sample GT:\n",
      "        DATE  GT_INFLAZIONE  GT_TEMATICO\n",
      "0 2004-01-01       3.486825    -6.522004\n",
      "1 2004-02-01       5.656006    -6.534317\n",
      "2 2004-03-01       4.820157    -8.017502\n",
      "3 2004-04-01       4.662026    -6.665120\n",
      "4 2004-05-01       4.382917    -7.179877\n"
     ]
    }
   ],
   "source": [
    "# Identifica colonne GT corrette\n",
    "print(\"Colonne GT disponibili:\")\n",
    "for i, col in enumerate(gt_monthly.columns):\n",
    "    print(f\"{i}: {col}\")\n",
    "\n",
    "# Seleziona colonne GT (aggiusta i nomi se necessario)\n",
    "date_col_gt = gt_monthly.columns[0]\n",
    "\n",
    "# Cerca colonne con inflazione e tematico\n",
    "gt_cols = []\n",
    "for col in gt_monthly.columns:\n",
    "    if 'inflazione' in col.lower() and 'pca' in col.lower():\n",
    "        gt_cols.append(col)\n",
    "    elif 'tematico' in col.lower():\n",
    "        gt_cols.append(col)\n",
    "\n",
    "print(f\"Colonne GT selezionate: {gt_cols}\")\n",
    "\n",
    "# Se non trovate, usa nomi manuali (aggiusta secondo la tua struttura)\n",
    "if len(gt_cols) < 2:\n",
    "    print(\"⚠️ Colonne GT non trovate automaticamente. Specifica manualmente:\")\n",
    "    print(\"Inserisci i nomi esatti delle colonne per:\")\n",
    "    print(\"1. Indice Inflazione GT\")\n",
    "    print(\"2. Indice Tematico GT\")\n",
    "    # Per ora uso nomi tipici - aggiusta se necessario\n",
    "    gt_cols = ['indice_Inflazione_GT_PCA_SA', 'indice_Tematico_GT_SA']\n",
    "\n",
    "gt_monthly_clean = gt_monthly[[date_col_gt] + gt_cols].copy()\n",
    "gt_monthly_clean.columns = ['DATE', 'GT_INFLAZIONE', 'GT_TEMATICO']\n",
    "gt_monthly_clean['DATE'] = pd.to_datetime(gt_monthly_clean['DATE'])\n",
    "\n",
    "# Filtra periodo\n",
    "gt_monthly_clean = gt_monthly_clean[\n",
    "    (gt_monthly_clean['DATE'] >= start_date) & \n",
    "    (gt_monthly_clean['DATE'] <= end_date)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nGT monthly preparati: {gt_monthly_clean.shape[0]} osservazioni\")\n",
    "print(\"Sample GT:\")\n",
    "print(gt_monthly_clean.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e3a9b",
   "metadata": {},
   "source": [
    "### Step 4: Preparazione dati NIC monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0bc3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne NIC disponibili:\n",
      "0: Periodo\n",
      "1: NIC_destag_ISTAT\n",
      "Colonne NIC trovate: ['NIC_destag_ISTAT']\n",
      "\n",
      "NIC monthly preparato: 237 osservazioni\n",
      "Sample NIC:\n",
      "        DATE   NIC  INFLATION_RATE\n",
      "0 2004-01-01  82.0             NaN\n",
      "1 2004-02-01  82.2        0.243902\n",
      "2 2004-03-01  82.5        0.364964\n",
      "3 2004-04-01  82.7        0.242424\n",
      "4 2004-05-01  82.9        0.241838\n"
     ]
    }
   ],
   "source": [
    "# Identifica colonne NIC\n",
    "print(\"Colonne NIC disponibili:\")\n",
    "for i, col in enumerate(nic_monthly.columns):\n",
    "    print(f\"{i}: {col}\")\n",
    "\n",
    "date_col_nic = nic_monthly.columns[0]\n",
    "\n",
    "# Cerca colonna NIC\n",
    "nic_cols = [col for col in nic_monthly.columns if 'nic' in col.lower()]\n",
    "print(f\"Colonne NIC trovate: {nic_cols}\")\n",
    "\n",
    "if len(nic_cols) == 0:\n",
    "    print(\"⚠️ Colonna NIC non trovata. Usa il nome esatto dalla lista sopra\")\n",
    "    # Usa nome tipico - aggiusta se necessario\n",
    "    nic_col = 'NIC_destag_ISTAT'\n",
    "else:\n",
    "    nic_col = nic_cols[0]\n",
    "\n",
    "nic_monthly_clean = nic_monthly[[date_col_nic, nic_col]].copy()\n",
    "nic_monthly_clean.columns = ['DATE', 'NIC']\n",
    "nic_monthly_clean['DATE'] = pd.to_datetime(nic_monthly_clean['DATE'])\n",
    "\n",
    "# Calcola inflation rate\n",
    "nic_monthly_clean['INFLATION_RATE'] = nic_monthly_clean['NIC'].pct_change() * 100\n",
    "\n",
    "# Filtra periodo\n",
    "nic_monthly_clean = nic_monthly_clean[\n",
    "    (nic_monthly_clean['DATE'] >= start_date) & \n",
    "    (nic_monthly_clean['DATE'] <= end_date)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nNIC monthly preparato: {nic_monthly_clean.shape[0]} osservazioni\")\n",
    "print(\"Sample NIC:\")\n",
    "print(nic_monthly_clean[['DATE', 'NIC', 'INFLATION_RATE']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a35ab",
   "metadata": {},
   "source": [
    "### Step 5: Merge finale e creazione dataset MIDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253648ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MIDAS base creato:\n",
      "Osservazioni: 236\n",
      "Periodo: da 2004-02-01 00:00:00 a 2023-09-01 00:00:00\n",
      "Colonne: ['DATE', 'INFLATION_RATE', 'GT_INFLAZIONE', 'GT_TEMATICO', 'YEAR_QUARTER', 'LABOR_SHARE', 'YEAR', 'MONTH']\n",
      "\n",
      "Sample dataset finale:\n",
      "        DATE  INFLATION_RATE  GT_INFLAZIONE  GT_TEMATICO  LABOR_SHARE\n",
      "0 2004-02-01        0.243902       5.656006    -6.534317    37.395267\n",
      "1 2004-03-01        0.364964       4.820157    -8.017502    37.395267\n",
      "2 2004-04-01        0.242424       4.662026    -6.665120    37.742574\n",
      "3 2004-05-01        0.241838       4.382917    -7.179877    37.742574\n",
      "4 2004-06-01        0.241255       1.974327    -6.448966    37.742574\n",
      "\n",
      "Statistiche base:\n",
      "       INFLATION_RATE  GT_INFLAZIONE  GT_TEMATICO  LABOR_SHARE\n",
      "count         236.000        236.000      236.000      236.000\n",
      "mean            0.163         -0.254       -0.363       39.469\n",
      "std             0.349          2.642        3.904        0.880\n",
      "min            -0.680         -3.685       -8.018       37.395\n",
      "25%             0.000         -2.053       -3.607       39.212\n",
      "50%             0.167         -1.336       -0.139       39.465\n",
      "75%             0.314          0.691        2.428       40.158\n",
      "max             3.415          8.886       11.504       41.206\n"
     ]
    }
   ],
   "source": [
    "# Merge dati monthly\n",
    "monthly_data = pd.merge(nic_monthly_clean[['DATE', 'INFLATION_RATE']], \n",
    "                       gt_monthly_clean, on='DATE', how='inner')\n",
    "\n",
    "# Rimuovi NaN dalla inflation rate\n",
    "monthly_data = monthly_data.dropna().reset_index(drop=True)\n",
    "\n",
    "# Crea mapping per Labor Share quarterly\n",
    "monthly_data['YEAR_QUARTER'] = monthly_data['DATE'].dt.to_period('Q')\n",
    "\n",
    "# Prepara Labor Share mapping\n",
    "labor_share_map = fred_data[['YEAR_QUARTER', 'LABOR_SHARE']].copy()\n",
    "\n",
    "# Merge con Labor Share\n",
    "midas_data = pd.merge(monthly_data, labor_share_map, on='YEAR_QUARTER', how='inner')\n",
    "\n",
    "# Aggiungi variabili aggiuntive\n",
    "midas_data['YEAR'] = midas_data['DATE'].dt.year\n",
    "midas_data['MONTH'] = midas_data['DATE'].dt.month\n",
    "\n",
    "print(\"Dataset MIDAS base creato:\")\n",
    "print(f\"Osservazioni: {midas_data.shape[0]}\")\n",
    "print(f\"Periodo: da {midas_data['DATE'].min()} a {midas_data['DATE'].max()}\")\n",
    "print(f\"Colonne: {midas_data.columns.tolist()}\")\n",
    "\n",
    "print(\"\\nSample dataset finale:\")\n",
    "print(midas_data[['DATE', 'INFLATION_RATE', 'GT_INFLAZIONE', 'GT_TEMATICO', 'LABOR_SHARE']].head())\n",
    "\n",
    "print(\"\\nStatistiche base:\")\n",
    "print(midas_data[['INFLATION_RATE', 'GT_INFLAZIONE', 'GT_TEMATICO', 'LABOR_SHARE']].describe().round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47449d6",
   "metadata": {},
   "source": [
    "### Step 6: Creazione lag e dummy per MIDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "996c5c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variabili MIDAS preparate:\n",
      "Osservazioni finali: 233\n",
      "Periodo: da 2004-05-01 00:00:00 a 2023-09-01 00:00:00\n",
      "\n",
      "Outlier gennaio 2022: 1 osservazioni\n",
      "Inflazione gennaio 2022: 1.59%\n",
      "Outlier ottobre 2022: 1 osservazioni\n",
      "Inflazione ottobre 2022: 3.42%\n",
      "\n",
      "Statistiche variabili chiave:\n",
      "       INFLATION_RATE  LABOR_SHARE  GT_INFLAZIONE_LAG3  GT_TEMATICO_LAG1  \\\n",
      "count         233.000      233.000             233.000           233.000   \n",
      "mean            0.162       39.494              -0.346            -0.336   \n",
      "std             0.351        0.856               2.529             3.843   \n",
      "min            -0.680       37.527              -3.685            -7.180   \n",
      "25%             0.000       39.216              -2.057            -3.568   \n",
      "50%             0.118       39.497              -1.351            -0.139   \n",
      "75%             0.313       40.158               0.640             2.427   \n",
      "max             3.415       41.206               8.886            11.504   \n",
      "\n",
      "       INFLATION_LAG1  \n",
      "count         233.000  \n",
      "mean            0.162  \n",
      "std             0.351  \n",
      "min            -0.680  \n",
      "25%             0.000  \n",
      "50%             0.118  \n",
      "75%             0.313  \n",
      "max             3.415  \n"
     ]
    }
   ],
   "source": [
    "# Crea lag per GT basati sui risultati Granger precedenti\n",
    "midas_data['GT_INFLAZIONE_LAG3'] = midas_data['GT_INFLAZIONE'].shift(3)\n",
    "midas_data['GT_TEMATICO_LAG1'] = midas_data['GT_TEMATICO'].shift(1)\n",
    "\n",
    "# Lag inflazione per componente backward-looking HNKPC\n",
    "midas_data['INFLATION_LAG1'] = midas_data['INFLATION_RATE'].shift(1)\n",
    "\n",
    "# Dummy outlier (monthly precision)\n",
    "midas_data['DUMMY_2022_01'] = ((midas_data['DATE'].dt.year == 2022) & \n",
    "                               (midas_data['DATE'].dt.month == 1)).astype(int)\n",
    "\n",
    "midas_data['DUMMY_2022_10'] = ((midas_data['DATE'].dt.year == 2022) & \n",
    "                               (midas_data['DATE'].dt.month == 10)).astype(int)\n",
    "\n",
    "# Rimuovi NaN dai lag\n",
    "midas_data_clean = midas_data.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Variabili MIDAS preparate:\")\n",
    "print(f\"Osservazioni finali: {midas_data_clean.shape[0]}\")\n",
    "print(f\"Periodo: da {midas_data_clean['DATE'].min()} a {midas_data_clean['DATE'].max()}\")\n",
    "\n",
    "# Verifica outlier\n",
    "outlier_2022_01 = midas_data_clean[midas_data_clean['DUMMY_2022_01'] == 1]\n",
    "outlier_2022_10 = midas_data_clean[midas_data_clean['DUMMY_2022_10'] == 1]\n",
    "\n",
    "print(f\"\\nOutlier gennaio 2022: {len(outlier_2022_01)} osservazioni\")\n",
    "if len(outlier_2022_01) > 0:\n",
    "    print(f\"Inflazione gennaio 2022: {outlier_2022_01['INFLATION_RATE'].values[0]:.2f}%\")\n",
    "\n",
    "print(f\"Outlier ottobre 2022: {len(outlier_2022_10)} osservazioni\")\n",
    "if len(outlier_2022_10) > 0:\n",
    "    print(f\"Inflazione ottobre 2022: {outlier_2022_10['INFLATION_RATE'].values[0]:.2f}%\")\n",
    "\n",
    "# Mostra statistiche finali\n",
    "key_vars = ['INFLATION_RATE', 'LABOR_SHARE', 'GT_INFLAZIONE_LAG3', 'GT_TEMATICO_LAG1', 'INFLATION_LAG1']\n",
    "print(\"\\nStatistiche variabili chiave:\")\n",
    "print(midas_data_clean[key_vars].describe().round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a1880a",
   "metadata": {},
   "source": [
    "### Step 7: Implementazione classe MIDAS custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a7442de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe MIDAS implementata ✓\n"
     ]
    }
   ],
   "source": [
    "class MIDAS_Regressor:\n",
    "    \"\"\"\n",
    "    Implementazione MIDAS semplificata per mixed-frequency data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, m=3):\n",
    "        \"\"\"\n",
    "        m: numero di osservazioni high-freq per low-freq (3 mesi per trimestre)\n",
    "        \"\"\"\n",
    "        self.m = m\n",
    "        self.params = None\n",
    "        self.fitted_values = None\n",
    "        self.residuals = None\n",
    "        self.aic = None\n",
    "        self.bic = None\n",
    "        self.rsquared = None\n",
    "        \n",
    "    def beta_weights(self, theta1, theta2):\n",
    "        \"\"\"Calcola pesi MIDAS usando distribuzione Beta\"\"\"\n",
    "        k = np.arange(1, self.m + 1)\n",
    "        weights = (k / self.m)**(theta1 - 1) * (1 - k / self.m)**(theta2 - 1)\n",
    "        # Normalizza\n",
    "        weights = weights / np.sum(weights)\n",
    "        return weights\n",
    "    \n",
    "    def create_midas_matrix(self, y, x_high_freq, x_low_freq, theta1, theta2):\n",
    "        \"\"\"Crea matrice X per regressione MIDAS\"\"\"\n",
    "        n_obs = len(y)\n",
    "        weights = self.beta_weights(theta1, theta2)\n",
    "        \n",
    "        # Inizializza matrice X con costante\n",
    "        X = np.ones((n_obs, 1))\n",
    "        \n",
    "        # Aggiungi variabili low-frequency (Labor Share)\n",
    "        if x_low_freq is not None:\n",
    "            if len(x_low_freq.shape) == 1:\n",
    "                X = np.column_stack([X, x_low_freq])\n",
    "            else:\n",
    "                X = np.column_stack([X, x_low_freq])\n",
    "        \n",
    "        # Aggiungi variabili high-frequency pesate con MIDAS\n",
    "        for col_idx in range(x_high_freq.shape[1]):\n",
    "            weighted_series = np.zeros(n_obs)\n",
    "            \n",
    "            for obs_idx in range(self.m, n_obs):  # Inizia da m per avere abbastanza lag\n",
    "                # Prendi m osservazioni precedenti\n",
    "                lag_values = x_high_freq.iloc[obs_idx-self.m:obs_idx, col_idx].values\n",
    "                # Applica pesi MIDAS (inverti ordine per lag structure)\n",
    "                weighted_series[obs_idx] = np.sum(lag_values[::-1] * weights)\n",
    "            \n",
    "            X = np.column_stack([X, weighted_series])\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def objective_function(self, params, y, x_high_freq, x_low_freq):\n",
    "        \"\"\"Funzione obiettivo da minimizzare (SSR)\"\"\"\n",
    "        try:\n",
    "            # Parametri: [theta1, theta2, betas...]\n",
    "            theta1, theta2 = params[:2]\n",
    "            betas = params[2:]\n",
    "            \n",
    "            # Crea matrice X\n",
    "            X = self.create_midas_matrix(y, x_high_freq, x_low_freq, theta1, theta2)\n",
    "            \n",
    "            # Rimuovi prime m osservazioni (per lag structure)\n",
    "            X_clean = X[self.m:]\n",
    "            y_clean = y[self.m:]\n",
    "            \n",
    "            # Regressione OLS\n",
    "            fitted_values = X_clean @ betas\n",
    "            residuals = y_clean - fitted_values\n",
    "            \n",
    "            return np.sum(residuals**2)\n",
    "        \n",
    "        except:\n",
    "            return 1e10  # Penalizza parametri non validi\n",
    "    \n",
    "    def fit(self, y, x_high_freq, x_low_freq=None, initial_theta=[1.5, 1.5]):\n",
    "        \"\"\"Stima modello MIDAS\"\"\"\n",
    "        \n",
    "        # Conta parametri\n",
    "        n_high = x_high_freq.shape[1]\n",
    "        n_low = 1 if x_low_freq is not None else 0\n",
    "        n_betas = 1 + n_low + n_high  # costante + low-freq + high-freq\n",
    "        \n",
    "        # Parametri iniziali: [theta1, theta2, beta_const, beta_low, beta_high...]\n",
    "        initial_params = initial_theta + [0.1] * n_betas\n",
    "        \n",
    "        # Bounds: theta > 0.1, betas liberi\n",
    "        bounds = [(0.1, 10), (0.1, 10)] + [(-10, 10)] * n_betas\n",
    "        \n",
    "        # Ottimizzazione\n",
    "        result = minimize(\n",
    "            self.objective_function,\n",
    "            initial_params,\n",
    "            args=(y, x_high_freq, x_low_freq),\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds,\n",
    "            options={'maxiter': 1000}\n",
    "        )\n",
    "        \n",
    "        if result.success:\n",
    "            self.params = result.x\n",
    "            \n",
    "            # Calcola fitted values e residui\n",
    "            theta1, theta2 = self.params[:2]\n",
    "            betas = self.params[2:]\n",
    "            \n",
    "            X = self.create_midas_matrix(y, x_high_freq, x_low_freq, theta1, theta2)\n",
    "            X_clean = X[self.m:]\n",
    "            y_clean = y[self.m:]\n",
    "            \n",
    "            self.fitted_values = X_clean @ betas\n",
    "            self.residuals = y_clean - self.fitted_values\n",
    "            \n",
    "            # Calcola metriche\n",
    "            n_obs = len(y_clean)\n",
    "            k_params = len(betas)\n",
    "            \n",
    "            ssr = np.sum(self.residuals**2)\n",
    "            tss = np.sum((y_clean - np.mean(y_clean))**2)\n",
    "            \n",
    "            self.rsquared = 1 - ssr/tss\n",
    "            self.aic = n_obs * np.log(ssr/n_obs) + 2 * k_params\n",
    "            self.bic = n_obs * np.log(ssr/n_obs) + k_params * np.log(n_obs)\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Ottimizzazione fallita: {result.message}\")\n",
    "            return False\n",
    "\n",
    "print(\"Classe MIDAS implementata ✓\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464bf24",
   "metadata": {},
   "source": [
    "### Step 8: Test della classe MIDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb2f5260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test classe MIDAS...\n",
      "Variabili test:\n",
      "y (inflation): 233 obs, range: -0.68 to 3.42\n",
      "x_high (GT): (233, 2)\n",
      "x_low (labor_share): 233 obs, range: 37.5 to 41.2\n",
      "\n",
      "Stima MIDAS in corso...\n",
      "Ottimizzazione fallita: ABNORMAL: \n",
      "❌ Stima MIDAS fallita\n"
     ]
    }
   ],
   "source": [
    "# Test su dataset semplificato\n",
    "print(\"Test classe MIDAS...\")\n",
    "\n",
    "# Prepara variabili per test\n",
    "y_test = midas_data_clean['INFLATION_RATE'].values\n",
    "x_high_test = midas_data_clean[['GT_INFLAZIONE_LAG3', 'GT_TEMATICO_LAG1']]\n",
    "x_low_test = midas_data_clean['LABOR_SHARE'].values\n",
    "\n",
    "print(f\"Variabili test:\")\n",
    "print(f\"y (inflation): {len(y_test)} obs, range: {y_test.min():.2f} to {y_test.max():.2f}\")\n",
    "print(f\"x_high (GT): {x_high_test.shape}\")\n",
    "print(f\"x_low (labor_share): {len(x_low_test)} obs, range: {x_low_test.min():.1f} to {x_low_test.max():.1f}\")\n",
    "\n",
    "# Istanzia e stima MIDAS\n",
    "midas = MIDAS_Regressor(m=3)\n",
    "\n",
    "print(\"\\nStima MIDAS in corso...\")\n",
    "success = midas.fit(y_test, x_high_test, x_low_test)\n",
    "\n",
    "if success:\n",
    "    print(\"✅ MIDAS stimato con successo!\")\n",
    "    print(f\"Parametri: {midas.params}\")\n",
    "    print(f\"R-squared: {midas.rsquared:.4f}\")\n",
    "    print(f\"AIC: {midas.aic:.2f}\")\n",
    "    print(f\"BIC: {midas.bic:.2f}\")\n",
    "    \n",
    "    # Mostra pesi MIDAS stimati\n",
    "    theta1, theta2 = midas.params[:2]\n",
    "    weights = midas.beta_weights(theta1, theta2)\n",
    "    print(f\"\\nPesi MIDAS stimati:\")\n",
    "    for i, w in enumerate(weights):\n",
    "        print(f\"  Lag {i+1}: {w:.3f}\")\n",
    "else:\n",
    "    print(\"❌ Stima MIDAS fallita\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ee43dc",
   "metadata": {},
   "source": [
    "### Step 9: Versione MIDAS robusta con debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d88cdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe MIDAS robusta implementata ✓\n"
     ]
    }
   ],
   "source": [
    "class MIDAS_Regressor_Robust:\n",
    "    \"\"\"\n",
    "    Versione robusta di MIDAS con debug e gestione errori migliorata\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, m=3):\n",
    "        self.m = m\n",
    "        self.params = None\n",
    "        self.fitted_values = None\n",
    "        self.residuals = None\n",
    "        self.aic = None\n",
    "        self.bic = None\n",
    "        self.rsquared = None\n",
    "        self.debug_info = {}\n",
    "        \n",
    "    def beta_weights(self, theta1, theta2):\n",
    "        \"\"\"Calcola pesi MIDAS con controlli numerici\"\"\"\n",
    "        try:\n",
    "            # Assicura che theta siano positivi\n",
    "            theta1 = max(theta1, 0.1)\n",
    "            theta2 = max(theta2, 0.1)\n",
    "            \n",
    "            k = np.arange(1, self.m + 1) / self.m  # Normalizza a [0,1]\n",
    "            \n",
    "            # Calcola pesi Beta\n",
    "            weights = k**(theta1 - 1) * (1 - k)**(theta2 - 1)\n",
    "            \n",
    "            # Controlla per NaN o infiniti\n",
    "            if np.any(~np.isfinite(weights)):\n",
    "                return np.ones(self.m) / self.m  # Pesi uniformi come fallback\n",
    "            \n",
    "            # Normalizza\n",
    "            weights = weights / np.sum(weights)\n",
    "            return weights\n",
    "            \n",
    "        except:\n",
    "            return np.ones(self.m) / self.m  # Fallback sicuro\n",
    "    \n",
    "    def create_simple_midas(self, y, x_high_freq, x_low_freq, theta1, theta2):\n",
    "        \"\"\"Versione semplificata per debug\"\"\"\n",
    "        n_obs = len(y)\n",
    "        weights = self.beta_weights(theta1, theta2)\n",
    "        \n",
    "        # Matrice X: [costante, labor_share, GT_weighted1, GT_weighted2]\n",
    "        X = np.ones((n_obs, 1))  # Costante\n",
    "        \n",
    "        # Labor Share (low frequency)\n",
    "        X = np.column_stack([X, x_low_freq])\n",
    "        \n",
    "        # GT pesati (high frequency) - versione semplificata\n",
    "        for col_idx in range(x_high_freq.shape[1]):\n",
    "            weighted_col = np.zeros(n_obs)\n",
    "            \n",
    "            # Per ogni osservazione, calcola media pesata degli ultimi m valori\n",
    "            for i in range(self.m, n_obs):\n",
    "                lag_values = x_high_freq.iloc[i-self.m:i, col_idx].values\n",
    "                weighted_col[i] = np.sum(lag_values * weights[::-1])  # Inverti per struttura lag\n",
    "            \n",
    "            X = np.column_stack([X, weighted_col])\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def objective_simple(self, params, y, x_high_freq, x_low_freq):\n",
    "        \"\"\"Funzione obiettivo semplificata\"\"\"\n",
    "        try:\n",
    "            theta1, theta2 = params[:2]\n",
    "            betas = params[2:]\n",
    "            \n",
    "            # Crea matrice X\n",
    "            X = self.create_simple_midas(y, x_high_freq, x_low_freq, theta1, theta2)\n",
    "            \n",
    "            # Usa solo osservazioni con dati completi\n",
    "            valid_idx = self.m\n",
    "            X_valid = X[valid_idx:]\n",
    "            y_valid = y[valid_idx:]\n",
    "            \n",
    "            # OLS\n",
    "            y_pred = X_valid @ betas\n",
    "            residuals = y_valid - y_pred\n",
    "            ssr = np.sum(residuals**2)\n",
    "            \n",
    "            # Penalizza se SSR non è finito\n",
    "            if not np.isfinite(ssr):\n",
    "                return 1e10\n",
    "                \n",
    "            return ssr\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.debug_info['last_error'] = str(e)\n",
    "            return 1e10\n",
    "    \n",
    "    def fit_simple(self, y, x_high_freq, x_low_freq):\n",
    "        \"\"\"Stima semplificata con multiple starting points\"\"\"\n",
    "        \n",
    "        # Numero parametri: 2 theta + 4 beta (const, labor_share, GT1, GT2)\n",
    "        n_params = 2 + 4\n",
    "        \n",
    "        # Multiple starting points per robustezza\n",
    "        starting_points = [\n",
    "            [1.0, 1.0, 0.0, 0.1, 0.05, 0.05],  # Conservative\n",
    "            [2.0, 2.0, 0.0, 0.2, 0.1, 0.1],    # Moderate\n",
    "            [0.5, 0.5, 0.0, 0.05, 0.02, 0.02], # Aggressive\n",
    "        ]\n",
    "        \n",
    "        best_result = None\n",
    "        best_objective = np.inf\n",
    "        \n",
    "        for i, start_params in enumerate(starting_points):\n",
    "            print(f\"Tentativo {i+1}/3 con starting point: {start_params[:2]}\")\n",
    "            \n",
    "            bounds = [(0.1, 5.0), (0.1, 5.0)] + [(-1.0, 1.0)] * 4\n",
    "            \n",
    "            try:\n",
    "                result = minimize(\n",
    "                    self.objective_simple,\n",
    "                    start_params,\n",
    "                    args=(y, x_high_freq, x_low_freq),\n",
    "                    method='L-BFGS-B',\n",
    "                    bounds=bounds,\n",
    "                    options={'maxiter': 500, 'ftol': 1e-6}\n",
    "                )\n",
    "                \n",
    "                if result.fun < best_objective:\n",
    "                    best_result = result\n",
    "                    best_objective = result.fun\n",
    "                    \n",
    "                print(f\"  Risultato: success={result.success}, objective={result.fun:.2f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Errore: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if best_result is not None and best_result.success:\n",
    "            self.params = best_result.x\n",
    "            \n",
    "            # Calcola statistiche finali\n",
    "            theta1, theta2 = self.params[:2]\n",
    "            betas = self.params[2:]\n",
    "            \n",
    "            X = self.create_simple_midas(y, x_high_freq, x_low_freq, theta1, theta2)\n",
    "            X_valid = X[self.m:]\n",
    "            y_valid = y[self.m:]\n",
    "            \n",
    "            self.fitted_values = X_valid @ betas\n",
    "            self.residuals = y_valid - self.fitted_values\n",
    "            \n",
    "            # Metriche\n",
    "            n_obs = len(y_valid)\n",
    "            ssr = np.sum(self.residuals**2)\n",
    "            tss = np.sum((y_valid - np.mean(y_valid))**2)\n",
    "            \n",
    "            self.rsquared = 1 - ssr/tss\n",
    "            self.aic = n_obs * np.log(ssr/n_obs) + 2 * len(betas)\n",
    "            self.bic = n_obs * np.log(ssr/n_obs) + len(betas) * np.log(n_obs)\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\"Tutti i tentativi di ottimizzazione sono falliti\")\n",
    "            return False\n",
    "\n",
    "print(\"Classe MIDAS robusta implementata ✓\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d23f4e2",
   "metadata": {},
   "source": [
    "### Step 10: Test della versione robusta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "882835ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MIDAS robusta...\n",
      "Controllo dati input:\n",
      "y NaN: 0\n",
      "x_high NaN: 0\n",
      "x_low NaN: 0\n",
      "\n",
      "Stima MIDAS robusta...\n",
      "Tentativo 1/3 con starting point: [1.0, 1.0]\n",
      "  Risultato: success=False, objective=3272.16\n",
      "Tentativo 2/3 con starting point: [2.0, 2.0]\n",
      "  Risultato: success=True, objective=26.27\n",
      "Tentativo 3/3 con starting point: [0.5, 0.5]\n",
      "  Risultato: success=True, objective=26.85\n",
      "\n",
      "✅ MIDAS robusta stimata con successo!\n",
      "\n",
      "Parametri MIDAS:\n",
      "  Theta1 (primo param Beta): 0.100\n",
      "  Theta2 (secondo param Beta): 3.796\n",
      "  Beta costante: 0.496\n",
      "  Beta Labor Share: -0.008\n",
      "  Beta GT Inflazione: 0.037\n",
      "  Beta GT Tematico: 0.012\n",
      "\n",
      "Metriche:\n",
      "  R-squared: 0.0791\n",
      "  AIC: -490.99\n",
      "  BIC: -477.24\n",
      "  RMSE: 0.338\n",
      "\n",
      "Pesi MIDAS:\n",
      "  Mese t-3: 0.928\n",
      "  Mese t-2: 0.072\n",
      "  Mese t-1: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Test della versione robusta\n",
    "print(\"Test MIDAS robusta...\")\n",
    "\n",
    "# Verifica dati input\n",
    "print(f\"Controllo dati input:\")\n",
    "print(f\"y NaN: {np.sum(np.isnan(y_test))}\")\n",
    "print(f\"x_high NaN: {np.sum(np.isnan(x_high_test.values))}\")\n",
    "print(f\"x_low NaN: {np.sum(np.isnan(x_low_test))}\")\n",
    "\n",
    "# Istanzia versione robusta\n",
    "midas_robust = MIDAS_Regressor_Robust(m=3)\n",
    "\n",
    "print(\"\\nStima MIDAS robusta...\")\n",
    "success = midas_robust.fit_simple(y_test, x_high_test, x_low_test)\n",
    "\n",
    "if success:\n",
    "    print(\"\\n✅ MIDAS robusta stimata con successo!\")\n",
    "    \n",
    "    # Risultati\n",
    "    theta1, theta2 = midas_robust.params[:2]\n",
    "    betas = midas_robust.params[2:]\n",
    "    \n",
    "    print(f\"\\nParametri MIDAS:\")\n",
    "    print(f\"  Theta1 (primo param Beta): {theta1:.3f}\")\n",
    "    print(f\"  Theta2 (secondo param Beta): {theta2:.3f}\")\n",
    "    print(f\"  Beta costante: {betas[0]:.3f}\")\n",
    "    print(f\"  Beta Labor Share: {betas[1]:.3f}\")\n",
    "    print(f\"  Beta GT Inflazione: {betas[2]:.3f}\")\n",
    "    print(f\"  Beta GT Tematico: {betas[3]:.3f}\")\n",
    "    \n",
    "    print(f\"\\nMetriche:\")\n",
    "    print(f\"  R-squared: {midas_robust.rsquared:.4f}\")\n",
    "    print(f\"  AIC: {midas_robust.aic:.2f}\")\n",
    "    print(f\"  BIC: {midas_robust.bic:.2f}\")\n",
    "    print(f\"  RMSE: {np.sqrt(np.mean(midas_robust.residuals**2)):.3f}\")\n",
    "    \n",
    "    # Pesi MIDAS\n",
    "    weights = midas_robust.beta_weights(theta1, theta2)\n",
    "    print(f\"\\nPesi MIDAS:\")\n",
    "    for i, w in enumerate(weights):\n",
    "        print(f\"  Mese t-{3-i}: {w:.3f}\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ Anche la versione robusta è fallita\")\n",
    "    if 'last_error' in midas_robust.debug_info:\n",
    "        print(f\"Ultimo errore: {midas_robust.debug_info['last_error']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c233ef",
   "metadata": {},
   "source": [
    "### Step 11: Stima modelli di confronto per valutazione MIDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1d2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset confronto: 230 osservazioni\n",
      "Periodo: da 2004-08-01 00:00:00 a 2023-09-01 00:00:00\n",
      "Variabile dipendente - Range: -0.68 to 3.42\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Prepara dataset per confronti (stesso sample MIDAS)\n",
    "# MIDAS usa osservazioni da index m=3 in poi\n",
    "start_idx = 3\n",
    "comparison_data = midas_data_clean.iloc[start_idx:].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset confronto: {len(comparison_data)} osservazioni\")\n",
    "print(f\"Periodo: da {comparison_data['DATE'].min()} a {comparison_data['DATE'].max()}\")\n",
    "\n",
    "# Variabile dipendente\n",
    "y_comp = comparison_data['INFLATION_RATE'].values\n",
    "\n",
    "print(f\"Variabile dipendente - Range: {y_comp.min():.2f} to {y_comp.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f28bd9",
   "metadata": {},
   "source": [
    "### Step 12: Modello 1 - HNKPC semplice (senza GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc9b7796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODELLO 1: HNKPC BASE ===\n",
      "R-squared: 0.4779\n",
      "AIC: 33.21\n",
      "BIC: 50.40\n",
      "RMSE: 0.254\n",
      "\n",
      "Coefficienti:\n",
      "  const: 0.2094  (p=0.796)\n",
      "  LABOR_SHARE: -0.0024  (p=0.906)\n",
      "  INFLATION_LAG1: 0.1779 ** (p=0.001)\n",
      "  DUMMY_2022_01: 1.4172 *** (p=0.000)\n",
      "  DUMMY_2022_10: 3.2580 *** (p=0.000)\n"
     ]
    }
   ],
   "source": [
    "# HNKPC base: π_t = const + λ*LS_t + γ_b*π_{t-1} + dummy + ε_t\n",
    "X_hnkpc_base = comparison_data[['LABOR_SHARE', 'INFLATION_LAG1', 'DUMMY_2022_01', 'DUMMY_2022_10']].copy()\n",
    "X_hnkpc_base = sm.add_constant(X_hnkpc_base)\n",
    "\n",
    "# Stima OLS con errori robusti\n",
    "model_hnkpc_base = sm.OLS(y_comp, X_hnkpc_base).fit(cov_type='HAC', cov_kwds={'maxlags': 3})\n",
    "\n",
    "print(\"=== MODELLO 1: HNKPC BASE ===\")\n",
    "print(f\"R-squared: {model_hnkpc_base.rsquared:.4f}\")\n",
    "print(f\"AIC: {model_hnkpc_base.aic:.2f}\")\n",
    "print(f\"BIC: {model_hnkpc_base.bic:.2f}\")\n",
    "\n",
    "# Calcola RMSE manualmente\n",
    "fitted_hnkpc_base = model_hnkpc_base.fittedvalues\n",
    "rmse_hnkpc_base = np.sqrt(mean_squared_error(y_comp, fitted_hnkpc_base))\n",
    "print(f\"RMSE: {rmse_hnkpc_base:.3f}\")\n",
    "\n",
    "# Coefficienti significativi\n",
    "print(\"\\nCoefficienti:\")\n",
    "for i, (name, coef, pval) in enumerate(zip(X_hnkpc_base.columns, model_hnkpc_base.params, model_hnkpc_base.pvalues)):\n",
    "    sig = \"***\" if pval < 0.001 else \"**\" if pval < 0.01 else \"*\" if pval < 0.05 else \"\"\n",
    "    print(f\"  {name}: {coef:.4f} {sig} (p={pval:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5cdc63",
   "metadata": {},
   "source": [
    "### Step 13: Modello 2 - HNKPC + GT (OLS tradizionale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be286dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODELLO 2: HNKPC + GT (OLS) ===\n",
      "R-squared: 0.4930\n",
      "AIC: 30.46\n",
      "BIC: 54.53\n",
      "RMSE: 0.251\n",
      "\n",
      "Coefficienti:\n",
      "  const: -0.4266  (p=0.689)\n",
      "  LABOR_SHARE: 0.0140  (p=0.605)\n",
      "  INFLATION_LAG1: 0.1417 ** (p=0.008)\n",
      "  GT_INFLAZIONE_LAG3: 0.0192 * (p=0.043)\n",
      "  GT_TEMATICO_LAG1: -0.0031  (p=0.630)\n",
      "  DUMMY_2022_01: 1.3997 *** (p=0.000)\n",
      "  DUMMY_2022_10: 3.1010 *** (p=0.000)\n"
     ]
    }
   ],
   "source": [
    "# HNKPC + GT: π_t = const + λ*LS_t + γ_b*π_{t-1} + α1*GT_Infl + α2*GT_Tem + dummy + ε_t\n",
    "X_hnkpc_gt = comparison_data[['LABOR_SHARE', 'INFLATION_LAG1', 'GT_INFLAZIONE_LAG3', 'GT_TEMATICO_LAG1', 'DUMMY_2022_01', 'DUMMY_2022_10']].copy()\n",
    "X_hnkpc_gt = sm.add_constant(X_hnkpc_gt)\n",
    "\n",
    "# Stima OLS\n",
    "model_hnkpc_gt = sm.OLS(y_comp, X_hnkpc_gt).fit(cov_type='HAC', cov_kwds={'maxlags': 3})\n",
    "\n",
    "print(\"\\n=== MODELLO 2: HNKPC + GT (OLS) ===\")\n",
    "print(f\"R-squared: {model_hnkpc_gt.rsquared:.4f}\")\n",
    "print(f\"AIC: {model_hnkpc_gt.aic:.2f}\")\n",
    "print(f\"BIC: {model_hnkpc_gt.bic:.2f}\")\n",
    "\n",
    "fitted_hnkpc_gt = model_hnkpc_gt.fittedvalues\n",
    "rmse_hnkpc_gt = np.sqrt(mean_squared_error(y_comp, fitted_hnkpc_gt))\n",
    "print(f\"RMSE: {rmse_hnkpc_gt:.3f}\")\n",
    "\n",
    "print(\"\\nCoefficienti:\")\n",
    "for i, (name, coef, pval) in enumerate(zip(X_hnkpc_gt.columns, model_hnkpc_gt.params, model_hnkpc_gt.pvalues)):\n",
    "    sig = \"***\" if pval < 0.001 else \"**\" if pval < 0.01 else \"*\" if pval < 0.05 else \"\"\n",
    "    print(f\"  {name}: {coef:.4f} {sig} (p={pval:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b2807",
   "metadata": {},
   "source": [
    "### Step 14: Confronto finale dei tre modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76cb14ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONFRONTO FINALE MODELLI ===\n",
      "        Modello  R_squared       AIC       BIC    RMSE\n",
      "0    HNKPC_Base     0.4779   33.2144   50.4048  0.2545\n",
      "1  HNKPC_GT_OLS     0.4930   30.4593   54.5258  0.2508\n",
      "2      MIDAS_GT     0.0791 -490.9905 -477.2382  0.3380\n",
      "\n",
      "Miglioramenti RMSE rispetto a HNKPC Base:\n",
      "HNKPC + GT (OLS): +1.46%\n",
      "MIDAS + GT: -32.80%\n",
      "\n",
      "Migliore per metrica:\n",
      "R-squared: HNKPC_GT_OLS\n",
      "AIC (più basso): MIDAS_GT\n",
      "BIC (più basso): MIDAS_GT\n",
      "RMSE (più basso): HNKPC_GT_OLS\n"
     ]
    }
   ],
   "source": [
    "# Raccogli risultati\n",
    "results_summary = pd.DataFrame({\n",
    "    'Modello': ['HNKPC_Base', 'HNKPC_GT_OLS', 'MIDAS_GT'],\n",
    "    'R_squared': [\n",
    "        model_hnkpc_base.rsquared,\n",
    "        model_hnkpc_gt.rsquared, \n",
    "        midas_robust.rsquared\n",
    "    ],\n",
    "    'AIC': [\n",
    "        model_hnkpc_base.aic,\n",
    "        model_hnkpc_gt.aic,\n",
    "        midas_robust.aic\n",
    "    ],\n",
    "    'BIC': [\n",
    "        model_hnkpc_base.bic,\n",
    "        model_hnkpc_gt.bic,\n",
    "        midas_robust.bic\n",
    "    ],\n",
    "    'RMSE': [\n",
    "        rmse_hnkpc_base,\n",
    "        rmse_hnkpc_gt,\n",
    "        np.sqrt(np.mean(midas_robust.residuals**2))\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=== CONFRONTO FINALE MODELLI ===\")\n",
    "print(results_summary.round(4))\n",
    "\n",
    "# Test di significatività miglioramento\n",
    "def calculate_improvement(base_rmse, model_rmse):\n",
    "    return ((base_rmse - model_rmse) / base_rmse) * 100\n",
    "\n",
    "print(f\"\\nMiglioramenti RMSE rispetto a HNKPC Base:\")\n",
    "print(f\"HNKPC + GT (OLS): {calculate_improvement(rmse_hnkpc_base, rmse_hnkpc_gt):+.2f}%\")\n",
    "print(f\"MIDAS + GT: {calculate_improvement(rmse_hnkpc_base, np.sqrt(np.mean(midas_robust.residuals**2))):+.2f}%\")\n",
    "\n",
    "# Evidenzia il migliore per ogni metrica\n",
    "print(f\"\\nMigliore per metrica:\")\n",
    "print(f\"R-squared: {results_summary.loc[results_summary['R_squared'].idxmax(), 'Modello']}\")\n",
    "print(f\"AIC (più basso): {results_summary.loc[results_summary['AIC'].idxmin(), 'Modello']}\")\n",
    "print(f\"BIC (più basso): {results_summary.loc[results_summary['BIC'].idxmin(), 'Modello']}\")\n",
    "print(f\"RMSE (più basso): {results_summary.loc[results_summary['RMSE'].idxmin(), 'Modello']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62c17d5",
   "metadata": {},
   "source": [
    "### Step 15: Analisi dei pesi MIDAS e interpretazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4af4a2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALISI PESI MIDAS ===\n",
      "Parametri Beta distribution:\n",
      "  Theta1: 0.100\n",
      "  Theta2: 3.796\n",
      "\n",
      "Struttura temporale pesi:\n",
      "  Mese t-3: 92.8%\n",
      "  Mese t-2: 7.2%\n",
      "  Mese t-1: 0.0%\n",
      "  Totale: 100.0%\n",
      "\n",
      "Interpretazione:\n",
      "- FORTE concentrazione su lag t-3: GT anticipano inflazione di 3 mesi\n",
      "\n",
      "Coefficienti GT in MIDAS:\n",
      "  GT Inflazione: 0.0366\n",
      "  GT Tematico: 0.0117\n",
      "- GT Inflazione ha impatto MAGGIORE di GT Tematico\n"
     ]
    }
   ],
   "source": [
    "# Analisi dettagliata pesi MIDAS\n",
    "theta1, theta2 = midas_robust.params[:2]\n",
    "weights = midas_robust.beta_weights(theta1, theta2)\n",
    "\n",
    "print(\"=== ANALISI PESI MIDAS ===\")\n",
    "print(f\"Parametri Beta distribution:\")\n",
    "print(f\"  Theta1: {theta1:.3f}\")\n",
    "print(f\"  Theta2: {theta2:.3f}\")\n",
    "\n",
    "print(f\"\\nStruttura temporale pesi:\")\n",
    "total_weight = 0\n",
    "for i in range(3):\n",
    "    lag_months = 3 - i\n",
    "    print(f\"  Mese t-{lag_months}: {weights[i]:.1%}\")\n",
    "    total_weight += weights[i]\n",
    "print(f\"  Totale: {total_weight:.1%}\")\n",
    "\n",
    "# Interpretazione economica\n",
    "print(f\"\\nInterpretazione:\")\n",
    "if weights[0] > 0.8:\n",
    "    print(\"- FORTE concentrazione su lag t-3: GT anticipano inflazione di 3 mesi\")\n",
    "elif weights[0] > 0.5:\n",
    "    print(\"- MODERATA concentrazione su lag t-3: effetto ritardato prevalente\")\n",
    "else:\n",
    "    print(\"- Distribuzione UNIFORME: effetti distribuiti nel tempo\")\n",
    "\n",
    "# Significatività coefficienti GT in MIDAS\n",
    "gt_infl_coef = midas_robust.params[4]  # Beta GT Inflazione\n",
    "gt_tem_coef = midas_robust.params[5]   # Beta GT Tematico\n",
    "\n",
    "print(f\"\\nCoefficienti GT in MIDAS:\")\n",
    "print(f\"  GT Inflazione: {gt_infl_coef:.4f}\")\n",
    "print(f\"  GT Tematico: {gt_tem_coef:.4f}\")\n",
    "\n",
    "if gt_infl_coef > gt_tem_coef:\n",
    "    print(\"- GT Inflazione ha impatto MAGGIORE di GT Tematico\")\n",
    "else:\n",
    "    print(\"- GT Tematico ha impatto MAGGIORE di GT Inflazione\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789f347f",
   "metadata": {},
   "source": [
    "I risultati sono contrastanti e rivelano problemi metodologici.\n",
    "\n",
    "Problema principale: i risultati MIDAS mostrano anomalie evidenti:\n",
    "\n",
    "- AIC MIDAS = -490: Impossibilmente basso vs. HNKPC ~30-50\n",
    "- R² MIDAS = 0.08: Molto inferiore a HNKPC ~0.48-0.49\n",
    "- RMSE MIDAS peggiore: 0.338 vs. 0.25x degli altri modelli\n",
    "\n",
    "Diagnosi del problema\n",
    "L'AIC negativo indica:\n",
    "\n",
    "- Possibile errore nel calcolo (log di un numero molto piccolo)\n",
    "- Sample size differente tra modelli\n",
    "- Scaling problem nella stima MIDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635f49e0",
   "metadata": {},
   "source": [
    "### Step 16: Debug e correzione MIDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca5e1254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEBUG MIDAS ===\n",
      "Sample sizes:\n",
      "MIDAS: 230 osservazioni\n",
      "HNKPC: 230 osservazioni\n",
      "Y originale: 233 osservazioni\n",
      "\n",
      "Residui MIDAS:\n",
      "Media: -0.000247\n",
      "Std: 0.337982\n",
      "Min: -0.985\n",
      "Max: 2.877\n",
      "SSR: 26.273358\n",
      "\n",
      "Ricalcolo AIC:\n",
      "N osservazioni: 230\n",
      "K parametri: 6\n",
      "SSR: 26.273358\n",
      "MSE: 0.114232\n",
      "Log(MSE): -2.169524\n",
      "AIC manuale: -486.99\n",
      "AIC MIDAS class: -490.99\n",
      "Differenza: 4.00\n"
     ]
    }
   ],
   "source": [
    "# Debug dettagliato MIDAS\n",
    "print(\"=== DEBUG MIDAS ===\")\n",
    "\n",
    "# Verifica sample sizes\n",
    "print(f\"Sample sizes:\")\n",
    "print(f\"MIDAS: {len(midas_robust.residuals)} osservazioni\")\n",
    "print(f\"HNKPC: {len(comparison_data)} osservazioni\")\n",
    "print(f\"Y originale: {len(y_test)} osservazioni\")\n",
    "\n",
    "# Verifica residui MIDAS\n",
    "residuals = midas_robust.residuals\n",
    "print(f\"\\nResidui MIDAS:\")\n",
    "print(f\"Media: {np.mean(residuals):.6f}\")\n",
    "print(f\"Std: {np.std(residuals):.6f}\")\n",
    "print(f\"Min: {np.min(residuals):.3f}\")\n",
    "print(f\"Max: {np.max(residuals):.3f}\")\n",
    "print(f\"SSR: {np.sum(residuals**2):.6f}\")\n",
    "\n",
    "# Ricalcola AIC manualmente\n",
    "n_obs = len(residuals)\n",
    "k_params = 6  # 2 theta + 4 beta\n",
    "ssr = np.sum(residuals**2)\n",
    "mse = ssr / n_obs\n",
    "\n",
    "print(f\"\\nRicalcolo AIC:\")\n",
    "print(f\"N osservazioni: {n_obs}\")\n",
    "print(f\"K parametri: {k_params}\")\n",
    "print(f\"SSR: {ssr:.6f}\")\n",
    "print(f\"MSE: {mse:.6f}\")\n",
    "print(f\"Log(MSE): {np.log(mse):.6f}\")\n",
    "\n",
    "# AIC corretto\n",
    "aic_manual = n_obs * np.log(mse) + 2 * k_params\n",
    "print(f\"AIC manuale: {aic_manual:.2f}\")\n",
    "\n",
    "# Confronta con MIDAS calcolato\n",
    "print(f\"AIC MIDAS class: {midas_robust.aic:.2f}\")\n",
    "print(f\"Differenza: {aic_manual - midas_robust.aic:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a9bd6",
   "metadata": {},
   "source": [
    "### Step 17: Implementazione MIDAS corretta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d7a2e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MIDAS CORRETTO ===\n",
      "rsquared: 0.0791\n",
      "aic: -486.9905\n",
      "bic: -466.3620\n",
      "rmse: 0.3380\n",
      "n_obs: 230\n",
      "k_params: 6\n"
     ]
    }
   ],
   "source": [
    "# Implementa MIDAS con calcolo metriche corretto\n",
    "class MIDAS_Fixed:\n",
    "    def __init__(self, midas_object, y_original, start_idx=3):\n",
    "        self.midas = midas_object\n",
    "        self.y_original = y_original\n",
    "        self.start_idx = start_idx\n",
    "        \n",
    "    def recalculate_metrics(self):\n",
    "        \"\"\"Ricalcola metriche con metodologia consistente\"\"\"\n",
    "        residuals = self.midas.residuals\n",
    "        y_subset = self.y_original[self.start_idx:]\n",
    "        \n",
    "        n_obs = len(residuals)\n",
    "        k_params = len(self.midas.params)\n",
    "        \n",
    "        # SSR e MSE\n",
    "        ssr = np.sum(residuals**2)\n",
    "        mse = ssr / n_obs\n",
    "        \n",
    "        # TSS per R-squared\n",
    "        y_mean = np.mean(y_subset)\n",
    "        tss = np.sum((y_subset - y_mean)**2)\n",
    "        \n",
    "        # Metriche corrette\n",
    "        self.rsquared_corrected = 1 - ssr/tss\n",
    "        self.aic_corrected = n_obs * np.log(mse) + 2 * k_params\n",
    "        self.bic_corrected = n_obs * np.log(mse) + k_params * np.log(n_obs)\n",
    "        self.rmse_corrected = np.sqrt(mse)\n",
    "        \n",
    "        return {\n",
    "            'rsquared': self.rsquared_corrected,\n",
    "            'aic': self.aic_corrected, \n",
    "            'bic': self.bic_corrected,\n",
    "            'rmse': self.rmse_corrected,\n",
    "            'n_obs': n_obs,\n",
    "            'k_params': k_params\n",
    "        }\n",
    "\n",
    "# Applica correzione\n",
    "midas_fixed = MIDAS_Fixed(midas_robust, y_test, start_idx=3)\n",
    "metrics_corrected = midas_fixed.recalculate_metrics()\n",
    "\n",
    "print(\"\\n=== MIDAS CORRETTO ===\")\n",
    "for key, value in metrics_corrected.items():\n",
    "    if key in ['n_obs', 'k_params']:\n",
    "        print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c694f",
   "metadata": {},
   "source": [
    "### Step 18: Confronto finale corretto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff707ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONFRONTO CORRETTO ===\n",
      "              Modello  R_squared       AIC       BIC    RMSE  N_obs\n",
      "0          HNKPC_Base     0.4779   33.2144   50.4048  0.2545    230\n",
      "1        HNKPC_GT_OLS     0.4930   30.4593   54.5258  0.2508    230\n",
      "2  MIDAS_GT_Corrected     0.0791 -486.9905 -466.3620  0.3380    230\n",
      "\n",
      "Miglioramenti RMSE vs HNKPC Base:\n",
      "HNKPC + GT (OLS): +1.46%\n",
      "MIDAS + GT: -32.80%\n",
      "\n",
      "=== VALUTAZIONE FINALE ===\n",
      "✅ MIDAS superiore ad HNKPC+GT per AIC\n",
      "❌ MIDAS non superiore ad HNKPC+GT per RMSE\n"
     ]
    }
   ],
   "source": [
    "# Confronto con metriche corrette\n",
    "results_corrected = pd.DataFrame({\n",
    "    'Modello': ['HNKPC_Base', 'HNKPC_GT_OLS', 'MIDAS_GT_Corrected'],\n",
    "    'R_squared': [\n",
    "        model_hnkpc_base.rsquared,\n",
    "        model_hnkpc_gt.rsquared, \n",
    "        metrics_corrected['rsquared']\n",
    "    ],\n",
    "    'AIC': [\n",
    "        model_hnkpc_base.aic,\n",
    "        model_hnkpc_gt.aic,\n",
    "        metrics_corrected['aic']\n",
    "    ],\n",
    "    'BIC': [\n",
    "        model_hnkpc_base.bic,\n",
    "        model_hnkpc_gt.bic,\n",
    "        metrics_corrected['bic']\n",
    "    ],\n",
    "    'RMSE': [\n",
    "        rmse_hnkpc_base,\n",
    "        rmse_hnkpc_gt,\n",
    "        metrics_corrected['rmse']\n",
    "    ],\n",
    "    'N_obs': [\n",
    "        len(y_comp),\n",
    "        len(y_comp),\n",
    "        metrics_corrected['n_obs']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=== CONFRONTO CORRETTO ===\")\n",
    "print(results_corrected.round(4))\n",
    "\n",
    "# Ricalcola miglioramenti\n",
    "base_rmse = rmse_hnkpc_base\n",
    "ols_rmse = rmse_hnkpc_gt  \n",
    "midas_rmse = metrics_corrected['rmse']\n",
    "\n",
    "print(f\"\\nMiglioramenti RMSE vs HNKPC Base:\")\n",
    "print(f\"HNKPC + GT (OLS): {((base_rmse - ols_rmse) / base_rmse) * 100:+.2f}%\")\n",
    "print(f\"MIDAS + GT: {((base_rmse - midas_rmse) / base_rmse) * 100:+.2f}%\")\n",
    "\n",
    "# Valutazione finale\n",
    "print(f\"\\n=== VALUTAZIONE FINALE ===\")\n",
    "if metrics_corrected['aic'] < model_hnkpc_gt.aic:\n",
    "    print(\"✅ MIDAS superiore ad HNKPC+GT per AIC\")\n",
    "else:\n",
    "    print(\"❌ MIDAS non superiore ad HNKPC+GT per AIC\")\n",
    "\n",
    "if metrics_corrected['rmse'] < rmse_hnkpc_gt:\n",
    "    print(\"✅ MIDAS superiore ad HNKPC+GT per RMSE\")\n",
    "else:\n",
    "    print(\"❌ MIDAS non superiore ad HNKPC+GT per RMSE\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
