{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea756b89",
   "metadata": {},
   "source": [
    "## NIC SA (destagionalizzato)\n",
    "\n",
    "Dal momento che da esploradati.istat.it non è possibile estrarre una serie storica continuativa del NIC, si prova a fare richiesta per accedere all'API di ISTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35119865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELLA 0\n",
    "# Serve per assicurarsi di avere installato le versioni supportate delle librerie necessarie per l'esecuzione del codice\n",
    "\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install --upgrade pip setuptools\n",
    "#!{sys.executable} -m pip install --upgrade \"pandasdmx>=1.0.0\" \"pydantic>=1.10.0,<2.0.0\" --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3167a6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 00:32:42,676 - INFO - FASE 1: Controllo delle librerie di base (pydantic, pandasdmx)...\n",
      "2025-05-15 00:32:42,682 - INFO - Controllo librerie superato.\n",
      "\n",
      "2025-05-15 00:32:42,683 - INFO - FASE 2: Avvio estrazione dati ISTAT.\n",
      "2025-05-15 00:32:42,684 - INFO - Avvio dello script per scaricare i dati ISTAT...\n",
      "2025-05-15 00:32:42,688 - INFO - Inizializzazione del client ISTAT...\n",
      "2025-05-15 00:32:42,704 - INFO - Verifico la disponibilità del dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versione Python: 3.13.3 (main, Apr  8 2025, 13:54:08) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "Versione pydantic installata: 1.10.22\n",
      "Versione pandasdmx installata: 1.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 00:32:43,013 - ERROR - Errore durante la verifica dei dataset: 500 Server Error: Internal Server Error for url: https://sdmx.istat.it/SDMXWS/rest/dataflow/all/latest\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommaso/my_python_env/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3557: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Script per scaricare dati ISTAT con controllo versioni preliminare\n",
    "\n",
    "import sys\n",
    "import importlib # Usato per importare moduli dinamicamente e controllare errori\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Configurazione base del logging (verrà usata anche dallo script ISTAT)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def check_libraries_and_versions():\n",
    "    \"\"\"\n",
    "    Controlla la presenza e le versioni di pydantic e pandasdmx.\n",
    "    Restituisce \"True\" se le librerie necessarie sono importabili e le versioni sono stampate,\n",
    "    \"False\" altrimenti (specialmente se si verifica l'errore ForwardRef).\n",
    "    \"\"\"\n",
    "    print(f\"Versione Python: {sys.version}\")\n",
    "    all_ok = True\n",
    "    try:\n",
    "        pydantic_module = importlib.import_module(\"pydantic\")\n",
    "        print(f\"Versione pydantic installata: {pydantic_module.__version__}\")\n",
    "        # Verifico se la versione di pydantic è < 2.0.0 come desiderato\n",
    "        if not (pydantic_module.__version__.startswith(\"1.\")):\n",
    "            logger.warning(f\"ATTENZIONE: La versione di pydantic ({pydantic_module.__version__}) non è < 2.0.0. Potrebbero esserci problemi.\")\n",
    "            # Non imposto all_ok = False qui, ma è un avvertimento importante.\n",
    "    except ImportError:\n",
    "        print(\"LIBRERIA CRITICA MANCANTE: pydantic non è installato.\")\n",
    "        all_ok = False\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante l'import o il controllo versione di pydantic: {e}\")\n",
    "        all_ok = False\n",
    "\n",
    "    if not all_ok: return False # Se pydantic ha problemi, inutile continuare\n",
    "\n",
    "    try:\n",
    "        # pandasdmx viene importato qui per testare specificamente l'errore ForwardRef\n",
    "        # Se questo import fallisce, la funzione restituirà False\n",
    "        global pandasdmx_Request # Se l'import ha successo, rendiamo Request accessibile globalmente\n",
    "        from pandasdmx import Request as pdmx_Req\n",
    "        pandasdmx_Request = pdmx_Req # Assegnazione per uso successivo\n",
    "\n",
    "        pandasdmx_module = importlib.import_module(\"pandasdmx\")\n",
    "        print(f\"Versione pandasdmx installata: {pandasdmx_module.__version__}\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"LIBRERIA CRITICA MANCANTE: pandasdmx non è installato.\")\n",
    "        all_ok = False\n",
    "    except TypeError as te:\n",
    "        # Questo è il passaggio cruciale per catturare l'errore ForwardRef\n",
    "        print(f\"ERRORE DI TIPO DURANTE L'IMPORT DI PANDASDMX: {te}\")\n",
    "        print(\"Questo è probabilmente l'errore 'ForwardRef._evaluate() missing ... recursive_guard'.\")\n",
    "        print(\"Sono stati eseguiti correttamente i comandi pip per installare pydantic < 2.0.0 e RIAVVIATO IL KERNEL???\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "        all_ok = False\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante l'import o il controllo versione di pandasdmx: {e}\")\n",
    "        all_ok = False\n",
    "        \n",
    "    return all_ok\n",
    "\n",
    "def run_istat_script():\n",
    "    \"\"\"\n",
    "    Contiene la logica principale per scaricare e processare i dati ISTAT.\n",
    "    Viene eseguito solo se check_libraries_and_versions() restituisce True.\n",
    "    \"\"\"\n",
    "    logger.info(\"Avvio dello script per scaricare i dati ISTAT...\")\n",
    "    \n",
    "    # pandasdmx.Request è stato reso disponibile come pandasdmx_Request\n",
    "    # se l'import in check_libraries_and_versions è riuscito.\n",
    "    global pandasdmx_Request\n",
    "\n",
    "    try:\n",
    "        # Inizializzo il client (cioè questo script) per ISTAT\n",
    "        logger.info(\"Inizializzazione del client ISTAT...\")\n",
    "        istat = pandasdmx_Request('ISTAT') # Uso la Request importata\n",
    "\n",
    "        # Verifica della disponibilità del dataset\n",
    "        logger.info(\"Verifico la disponibilità del dataset...\")\n",
    "        try:\n",
    "            available_dataflows = istat.dataflow()\n",
    "            if 'SDDS_PLUS_CPI_DF' not in available_dataflows.dataflow:\n",
    "                logger.error(\"Dataset SDDS_PLUS_CPI_DF non trovato.\")\n",
    "                alternative_datasets = [\n",
    "                    key for key in available_dataflows.dataflow.keys()\n",
    "                    if isinstance(key, str) and ('CPI' in key.upper() or 'PRICE' in key.upper())\n",
    "                ]\n",
    "                if alternative_datasets:\n",
    "                    logger.info(f\"Dataset alternativi disponibili: {alternative_datasets}\")\n",
    "                else:\n",
    "                    logger.info(\"Nessun dataset alternativo con 'CPI' o 'PRICE' trovato.\")\n",
    "                sys.exit(1)\n",
    "        except AttributeError as ae:\n",
    "            logger.error(f\"Errore nella struttura dell'oggetto dataflow restituito da istat.dataflow(): {ae}.\")\n",
    "            logger.info(f\"Tipo di oggetto restituito: {type(available_dataflows)}. Contenuto (parziale): {str(available_dataflows)[:500]}\")\n",
    "            sys.exit(1)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Errore durante la verifica dei dataset: {e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        # Tento due approcci: prima con destagionalizzazione, poi senza se necessario\n",
    "        adjustments_to_try = ['SA', None]\n",
    "        data = None\n",
    "        success = False\n",
    "        successful_adjustment = None\n",
    "\n",
    "        for adjustment_value in adjustments_to_try:\n",
    "            try:\n",
    "                key_params = {\n",
    "                    'FREQ': 'M', 'REF_AREA': 'IT', 'MEASURE': 'I',\n",
    "                    'PRICE': 'CP00', 'UNIT_MEASURE': 'INX',\n",
    "                }\n",
    "                if adjustment_value:\n",
    "                    key_params['ADJUSTMENT'] = adjustment_value\n",
    "                \n",
    "                logger.info(f\"Richiesta dati con parametri: {key_params}\")\n",
    "                resp = istat.data(\n",
    "                    resource_id='SDDS_PLUS_CPI_DF',\n",
    "                    key=key_params,\n",
    "                    params={'startPeriod': '2004-01', 'endPeriod': '2024-12'}\n",
    "                )\n",
    "                \n",
    "                # Verifico se ci sono serie di dati nella risposta\n",
    "                # Alcune versioni/implementazioni di SDMX potrebbero non avere resp.series,\n",
    "                # o potrebbe essere vuoto se non ci sono dati.\n",
    "                # to_pandas() dovrebbe comunque gestire la situazione.\n",
    "                if not hasattr(resp, 'series') or not list(resp.series):\n",
    "                    # Tento comunque di convertire in pandas, potrebbe esserci un dataset vuoto\n",
    "                    logger.warning(f\"La risposta non sembra contenere serie di dati esplicite con adjustment={adjustment_value}. Tentativo di conversione...\")\n",
    "\n",
    "                data_df = resp.to_pandas() # Converto in pandas DataFrame/Series\n",
    "\n",
    "                if data_df.empty:\n",
    "                    logger.warning(f\"Dataframe vuoto restituito da to_pandas() con adjustment={adjustment_value}\")\n",
    "                    continue\n",
    "                    \n",
    "                logger.info(f\"Dati ottenuti con successo con adjustment={adjustment_value}\")\n",
    "                data = data_df\n",
    "                success = True\n",
    "                successful_adjustment = adjustment_value\n",
    "                break # Esce dal loop al primo successo\n",
    "            except Exception as e_loop:\n",
    "                logger.warning(f\"Tentativo di recupero dati fallito con adjustment={adjustment_value}: {e_loop}\")\n",
    "                # import traceback ---> # Uncomment per debug dettagliato del loop\n",
    "                # logger.debug(traceback.format_exc())\n",
    "                continue\n",
    "        \n",
    "        if not success:\n",
    "            logger.error(\"Impossibile ottenere i dati con i parametri specificati dopo tutti i tentativi.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        # Log della struttura del dataframe prima della manipolazione\n",
    "        logger.info(f\"Tipo di dati restituiti da to_pandas(): {type(data)}\")\n",
    "        logger.info(f\"Prime righe del dataframe originale:\\n{data.head()}\")\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            logger.info(f\"Indici del dataframe: {data.index.names}\")\n",
    "            logger.info(f\"Colonne del dataframe originale: {data.columns.tolist()}\")\n",
    "        elif isinstance(data, pd.Series):\n",
    "            logger.info(f\"Indice della serie: {data.index.name if data.index.name else 'N/A'}\")\n",
    "            logger.info(f\"Nome della serie: {data.name if data.name else 'N/A'}\")\n",
    "\n",
    "        # Reset index con gestione di possibili strutture diverse\n",
    "        df = None\n",
    "        if isinstance(data, pd.Series):\n",
    "            df = data.reset_index()\n",
    "            # Se era una serie, la colonna dei valori potrebbe chiamarsi 0 o col nome della serie\n",
    "            if df.columns[-1] == 0 or df.columns[-1] == data.name:\n",
    "                 df.rename(columns={df.columns[-1]: 'OBS_VALUE'}, inplace=True)\n",
    "        elif isinstance(data, pd.DataFrame):\n",
    "            df = data.reset_index()\n",
    "        else:\n",
    "            logger.error(f\"Il tipo di dati {type(data)} non è un DataFrame o Series pandas supportato per l'elaborazione.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        logger.info(f\"Colonne dopo reset_index: {df.columns.tolist()}\")\n",
    "\n",
    "        # Identifico la colonna temporale e quella dei valori (vado a tentativi su nomi standard)\n",
    "        time_col, value_col = None, None\n",
    "        time_candidates = ['TIME_PERIOD', 'time_period', 'TIME', 'Time', 'time', 'Date', 'date', 'Period', 'period']\n",
    "        value_candidates = ['OBS_VALUE', 'obs_value', 'Value', 'value']\n",
    "\n",
    "        for tc in time_candidates:\n",
    "            if tc in df.columns: time_col = tc; break\n",
    "        for vc in value_candidates:\n",
    "            if vc in df.columns: value_col = vc; break\n",
    "        \n",
    "        # Fallback euristico se i nomi standard non sono trovati\n",
    "        if not time_col or not value_col:\n",
    "            logger.warning(\"Nomi colonna standard (TIME_PERIOD/OBS_VALUE) non trovati. Tentativo con euristica.\")\n",
    "            temp_cols = [col for col in df.columns if col not in ['FREQ', 'REF_AREA', 'MEASURE', 'PRICE', 'UNIT_MEASURE', 'ADJUSTMENT']]\n",
    "            \n",
    "            if not value_col: # Identifico colonna valore\n",
    "                for col_candidate in reversed(temp_cols): # Parto dal fondo, spesso il valore è l'ultima colonna non-dimensione\n",
    "                    if df[col_candidate].dtype in ('float64', 'int64', 'float32', 'int32', 'float', 'int'):\n",
    "                        value_col = col_candidate\n",
    "                        break\n",
    "                if not value_col and temp_cols: value_col = temp_cols[-1] # Ultima risorsa\n",
    "\n",
    "            if not time_col: # Identifico colonna tempo\n",
    "                for col_candidate in temp_cols:\n",
    "                    if col_candidate == value_col: continue\n",
    "                    # Controllo se la colonna contiene periodi o date\n",
    "                    if df[col_candidate].dtype == 'object' and \\\n",
    "                       df[col_candidate].dropna().astype(str).str.match(r'^\\d{4}(?:-\\d{2})?(?:[QMT]\\d{1,2})?$', na=False).any():\n",
    "                        time_col = col_candidate\n",
    "                        break\n",
    "                    # Potrebbe essere già un oggetto datetime/period se pandasdmx lo ha parsato\n",
    "                    elif pd.api.types.is_datetime64_any_dtype(df[col_candidate]) or \\\n",
    "                         isinstance(df[col_candidate].dtype, pd.PeriodDtype):\n",
    "                        time_col = col_candidate\n",
    "                        break\n",
    "        \n",
    "        if time_col and value_col:\n",
    "            logger.info(f\"Colonna temporale identificata: '{time_col}'\")\n",
    "            logger.info(f\"Colonna valore identificata: '{value_col}'\")\n",
    "\n",
    "            df_final = df[[time_col, value_col]].copy() # Uso .copy() per evitare SettingWithCopyWarning\n",
    "            df_final.columns = ['Time', 'Value']\n",
    "\n",
    "            try:\n",
    "                # Provo a convertire 'Time' in Periodo mensile per un ordinamento robusto\n",
    "                # Se è già un Periodo o Datetime, la conversione potrebbe essere diretta o non necessaria\n",
    "                if not isinstance(df_final['Time'].dtype, pd.PeriodDtype):\n",
    "                    df_final['Time'] = pd.to_datetime(df_final['Time']).dt.to_period('M')\n",
    "                logger.info(\"Colonna 'Time' convertita/verificata come pd.PeriodIndex (mensile).\")\n",
    "            except Exception as conv_err:\n",
    "                logger.warning(f\"Impossibile convertire la colonna 'Time' ('{time_col}') in Periodo mensile: {conv_err}. L'ordinamento si baserà sul tipo esistente.\")\n",
    "\n",
    "            df_final.sort_values('Time', inplace=True)\n",
    "\n",
    "            adjustment_suffix = 'RAW'\n",
    "            if successful_adjustment == 'SA':\n",
    "                adjustment_suffix = 'SA'\n",
    "            \n",
    "            output_file = f\"CPI_NIC_{adjustment_suffix}_Italy_2004_2024.csv\"\n",
    "            df_final.to_csv(output_file, index=False)\n",
    "            logger.info(f\"Dati salvati nel file: {output_file}\")\n",
    "\n",
    "            print(\"\\nPrime righe del dataset estratto:\")\n",
    "            print(df_final.head())\n",
    "            print(\"\\nStatistiche descrittive:\")\n",
    "            print(df_final['Value'].describe())\n",
    "            \n",
    "            missing = df_final['Value'].isna().sum()\n",
    "            if missing > 0:\n",
    "                print(f\"\\nValori mancanti nella colonna 'Value': {missing}\")\n",
    "            else:\n",
    "                print(\"\\nNessun valore mancante nella colonna 'Value'.\")\n",
    "        else:\n",
    "            logger.error(\"Impossibile identificare automaticamente le colonne temporali e/o di valore nel dataframe.\")\n",
    "            print(\"\\nStruttura del dataframe dopo il reset_index():\")\n",
    "            print(df.head())\n",
    "            print(\"\\nColonne disponibili:\", df.columns.tolist())\n",
    "            if time_col: print(f\"Colonna tempo tentata: {time_col}\")\n",
    "            else: print(\"Colonna tempo NON identificata.\")\n",
    "            if value_col: print(f\"Colonna valore tentata: {value_col}\")\n",
    "            else: print(\"Colonna valore NON identificata.\")\n",
    "\n",
    "    except Exception as e_main:\n",
    "        logger.error(f\"ERRORE CRITICO NELL'ESECUZIONE DELLO SCRIPT ISTAT: {e_main}\")\n",
    "        import traceback\n",
    "        logger.error(traceback.format_exc()) # Stampo il traceback completo per l'errore principale\n",
    "        if 'data' in locals() and data is not None: # Verifico se 'data' esiste ed è stato popolato\n",
    "            print(\"\\nStruttura del dataframe originale (se disponibile) che potrebbe aver causato l'errore:\")\n",
    "            print(data.head())\n",
    "        sys.exit(1) # Esce in caso di errore nello script principale\n",
    "\n",
    "# Blocco di esecuzione principale\n",
    "if __name__ == \"__main__\":\n",
    "    # Fase 1: Controllo delle librerie e delle versioni\n",
    "    logger.info(\"FASE 1: Controllo delle librerie di base (pydantic, pandasdmx)...\")\n",
    "    if check_libraries_and_versions():\n",
    "        logger.info(\"Controllo librerie superato.\\n\")\n",
    "        # Fase 2: Esecuzione dello script ISTAT\n",
    "        logger.info(\"FASE 2: Avvio estrazione dati ISTAT.\")\n",
    "        run_istat_script()\n",
    "    else:\n",
    "        logger.error(\"Script ISTAT non eseguito a causa di problemi con le librerie di base (pydantic/pandasdmx).\")\n",
    "        logger.error(\"Rivedi i messaggi di errore sopra. Assicurati di aver eseguito i comandi pip per installare/aggiornare le librerie e di aver RIAVVIATO IL KERNEL del notebook.\")\n",
    "        sys.exit(1) # Esce se il controllo delle librerie fallisce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8d2754",
   "metadata": {},
   "source": [
    "### Metodologia\n",
    "\n",
    "**Verifica della Connettività e Disponibilità del Dataflow**<br>\n",
    "Come primo passo, si stabilisce una connessione all'endpoint SDMX dell'ISTAT utilizzando la libreria pandasdmx. Si procede al recupero dell'elenco completo dei dataflow disponibili per accertare la funzionalità generale del servizio e per confermare la presenza del dataflow di interesse, identificato come SDDS_PLUS_CPI_DF.\n",
    "\n",
    "**Recupero e Analisi della Data Structure Definition (DSD)**<br>\n",
    "Una volta confermata la disponibilità del dataflow, si tenta di recuperare la sua DSD. La DSD è un artefatto SDMX cruciale che descrive la struttura dei dati, includendo l'elenco completo delle dimensioni, i loro identificativi, l'ordine previsto e le codelist associate a ciascuna dimensione.<br>\n",
    "L'analisi della DSD è fondamentale per comprendere come costruire correttamente la chiave di interrogazione (key) per la richiesta dati, specialmente alla luce delle modifiche segnalate da ISTAT. Si presterà attenzione all'ordine e agli ID esatti delle dimensioni come FREQ, REF_AREA, MEASURE, PRICE, UNIT_MEASURE, e ADJUSTMENT.\n",
    "\n",
    "**Costruzione della Query e Recupero dei Dati**<br>\n",
    "Sulla base delle informazioni estratte dalla DSD (in particolare l'ordine e gli ID delle dimensioni), si formula la key per la query dati. Si effettua quindi la richiesta dati al dataflow SDDS_PLUS_CPI_DF specificando i parametri per le dimensioni desiderate ('FREQ': 'M', 'REF_AREA': 'IT', 'MEASURE': 'I', 'PRICE': 'CP00', 'UNIT_MEASURE': 'INX'.) e il periodo temporale di interesse (startPeriod: '2004-01', endPeriod: '2024-12').<br>\n",
    "Si considera la possibilità di richiedere sia dati destagionalizzati (ADJUSTMENT='SA') sia dati grezzi (omettendo il parametro ADJUSTMENT o specificandone il valore appropriato se indicato dalla DSD per i dati non destagionalizzati).\n",
    "\n",
    "**Elaborazione e Salvataggio dei Dati**<br>\n",
    "I dati restituiti dal servizio SDMX vengono convertiti in un formato tabellare pandas.DataFrame. Il DataFrame viene processato per selezionare le colonne rilevanti (il periodo temporale e il valore dell'indice), rinominarle per chiarezza e ordinarle cronologicamente. Infine, i dati elaborati vengono salvati in un file CSV per successive analisi.\n",
    "\n",
    "**Gestione delle Problematiche Potenziali**<br>\n",
    "- *Errori del Server (es. HTTP 500)*. Se si verificano errori del server durante una qualsiasi fase, si considera la possibilità di problemi temporanei sul server ISTAT o di una non conformità della richiesta inviata rispetto alle aspettative del nuovo servizio SDMX-RI.<br>\n",
    "- *Mancato Recupero della DSD*. Se il recupero della DSD fallisce, ma l'elenco dei dataflow è accessibile, ciò potrebbe indicare un problema specifico con la DSD del dataflow SDDS_PLUS_CPI_DF sull'endpoint ISTAT. In tale scenario, la costruzione accurata della query diventa più complessa e dipendente da documentazione esterna o tentativi basati sulle convenzioni note.<br>\n",
    "- *Dati Mancanti o Inattesi*. Si verifica che i dati restituiti siano coerenti con le aspettative.\n",
    "\n",
    "\n",
    "**Errore rilevato**<br>\n",
    "L'output 500 Server Error: Internal Server Error for url: https://sdmx.istat.it/SDMXWS/rest/dataflow/all/latest attesta che il servizio SDMX dell'ISTAT non è funzionante o è instabile. Nonostante si sia provato ad accedervi più volte in giorni diversi, l'output non cambia.\n",
    "\n",
    "*Monitorare lo Stato del Servizio ISTAT*: Si può provare ad accedere periodicamente a https://sdmx.istat.it/SDMXWS/rest/dataflow/all/latest dal browser, oppure fare un check tramite uno script di controllo apposito, denominato ‘check_istat_sdmx_status.py’.\n",
    "\n",
    "Tuttavia, dopo aver eseguito più volte lo script ‘check_istat_sdmx_status.py’ dal terminale interno a VS Code, l'output restituito non cambia: ‘ERROR - Il servizio ISTAT SDMX NON sembra essere operativo al momento’. Si deve dunque procedere con l'estrazione manuale delle serie storiche."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_python_env)",
   "language": "python",
   "name": "my_python_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
